{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72e238ed",
      "metadata": {
        "id": "72e238ed"
      },
      "source": [
        "## import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "PEo1TScvvgb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEo1TScvvgb8",
        "outputId": "5ea0559e-d5d9-4afd-bfb0-516de13d1683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b63bb611",
      "metadata": {
        "id": "b63bb611"
      },
      "outputs": [],
      "source": [
        "# built-in\n",
        "import re, codecs\n",
        "import time\n",
        "import os\n",
        "\n",
        "# pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# nlp\n",
        "import nltk\n",
        "\n",
        "# sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# plottong\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f299bfc1",
      "metadata": {
        "id": "f299bfc1"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import KFold,train_test_split,cross_val_score,cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import classification_report,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "da0d09f4",
      "metadata": {
        "id": "da0d09f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "594fcb38",
      "metadata": {
        "id": "594fcb38"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    # tf.random.set_random_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seeds(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f496d699",
      "metadata": {
        "id": "f496d699"
      },
      "source": [
        "## read data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name_type = 'enpt' # en; all; enpt"
      ],
      "metadata": {
        "id": "PC5FuIyJQLhd"
      },
      "id": "PC5FuIyJQLhd",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# def read_semeval_data(data_type='train', language='EN'):\n",
        "#     base_path = '/content/drive/MyDrive/i2nlp_project/'\n",
        "#     if data_type == 'train':\n",
        "#         annotation = f'{base_path}/training_data/{language}/subtask-2-annotations.txt'\n",
        "#         directory_path = f'{base_path}/training_data/{language}/raw-documents'\n",
        "#     elif data_type == 'test':\n",
        "#         annotation = f'{base_path}/dev_data/{language}/subtask-2-annotations.txt'\n",
        "#         directory_path = f'{base_path}/dev_data/{language}/subtask-2-documents'\n",
        "\n",
        "\n",
        "#     label_info = pd.read_csv(annotation, sep='\\t', header=None)\n",
        "#     label_info.columns = ['filename', 'narrative', 'sub_narrative']\n",
        "\n",
        "#     file_info = []\n",
        "#     for filename in os.listdir(directory_path):\n",
        "#         file_path = os.path.join(directory_path, filename)\n",
        "#         if os.path.isfile(file_path):\n",
        "#             with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#                 file_info.append((filename, file.read()))\n",
        "\n",
        "#     text_df = pd.DataFrame(file_info, columns=['filename', 'text'])\n",
        "#     df = label_info.merge(text_df, on='filename', how='inner')\n",
        "#     df['language'] = language\n",
        "#     # df['narrative_labels'] = df['narrative'].apply(lambda x: x.split(';'))\n",
        "#     # df['sub_narrative_labels'] = df['sub_narrative'].apply(lambda x: x.split(';'))\n",
        "#     return df\n",
        "\n",
        "# train_df = pd.concat([\n",
        "#     read_semeval_data(data_type='train', language='EN'),\n",
        "#     # read_semeval_data(data_type='train', language='PT'),\n",
        "#     # read_semeval_data(data_type='train', language='BG'),\n",
        "#     # read_semeval_data(data_type='train', language='HI'),\n",
        "#     # read_semeval_data(data_type='train', language='RU')\n",
        "# ], ignore_index=True)\n",
        "# test_df = pd.concat([\n",
        "#     read_semeval_data(data_type='test', language='EN'),\n",
        "#     # read_semeval_data(data_type='test', language='PT'),\n",
        "#     # read_semeval_data(data_type='test', language='BG'),\n",
        "#     # read_semeval_data(data_type='test', language='HI'),\n",
        "#     # read_semeval_data(data_type='test', language='RU')\n",
        "# ], ignore_index=True)\n",
        "\n",
        "# train_df.to_csv(f'/content/drive/MyDrive/i2nlp_project/dataset/train_{dataset_name_type}.csv', index=False)\n",
        "# test_df.to_csv(f'/content/drive/MyDrive/i2nlp_project/dataset/test_{dataset_name_type}.csv', index=False)"
      ],
      "metadata": {
        "id": "jr-HC9F-gMA-"
      },
      "id": "jr-HC9F-gMA-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ce4ade4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4ade4b",
        "outputId": "5dc920fc-397f-4e83-f005-7727edc6de9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(799, 8) (76, 8)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(f'/content/drive/MyDrive/i2nlp_project/dataset/train_{dataset_name_type}.csv')\n",
        "test_df = pd.read_csv(f'/content/drive/MyDrive/i2nlp_project/dataset/test_{dataset_name_type}.csv')\n",
        "\n",
        "\n",
        "train_df['narrative_labels'] = train_df['narrative'].apply(lambda x: x.split(';'))\n",
        "test_df['narrative_labels'] = test_df['narrative'].apply(lambda x: x.split(';'))\n",
        "\n",
        "train_df['sub_narrative_labels'] = train_df['sub_narrative'].apply(lambda x: x.split(';'))\n",
        "test_df['sub_narrative_labels'] = test_df['sub_narrative'].apply(lambda x: x.split(';'))\n",
        "\n",
        "# train_df = train_df[train_df['language'] == 'EN']\n",
        "# test_df = test_df[test_df['language'] == 'EN']\n",
        "\n",
        "# print(train_df.groupby(['language', 'dataset_type', 'dataset_type_label'])[['filename']].agg('count').rename(columns={'filename': 'count'}))\n",
        "# print(test_df.groupby(['language', 'dataset_type', 'dataset_type_label'])[['filename']].agg('count').rename(columns={'filename': 'count'}))\n",
        "\n",
        "# train_df = train_df[(train_df.dataset_type == 'URW') & (train_df.language == 'EN')]\n",
        "# test_df= test_df[(test_df.dataset_type == 'URW') & (test_df.language == 'EN')]\n",
        "\n",
        "print(train_df.shape, test_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436ba8dc",
      "metadata": {
        "id": "436ba8dc"
      },
      "source": [
        "# Classification start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "MTewSencwpbG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTewSencwpbG",
        "outputId": "595be268-259a-4c2d-e3ba-ae17b2f5c8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "20ae1691",
      "metadata": {
        "id": "20ae1691"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "25078cea",
      "metadata": {
        "id": "25078cea"
      },
      "outputs": [],
      "source": [
        "# # Initialize tokenizer\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# # Tokenize and chunk data\n",
        "# def tokenize_and_chunk(documents, labels, chunk_size=512):\n",
        "#     inputs, targets = [], []\n",
        "#     for doc, label in zip(documents, labels):\n",
        "#         tokenized = tokenizer(doc, truncation=False, add_special_tokens=False)\n",
        "#         input_ids = tokenized[\"input_ids\"]\n",
        "#         chunks = [input_ids[i:i + chunk_size] for i in range(0, len(input_ids), chunk_size)]\n",
        "\n",
        "#         # Pad chunks to chunk_size\n",
        "#         for chunk in chunks:\n",
        "#             chunk += [tokenizer.pad_token_id] * (chunk_size - len(chunk))\n",
        "\n",
        "#         inputs.extend(chunks)\n",
        "#         targets.extend([label] * len(chunks))\n",
        "#     return inputs, targets\n",
        "\n",
        "\n",
        "# #-----------------TRAIN-----------------------\n",
        "# documents = train_df['text']\n",
        "# labels = train_df['narrative_labels']\n",
        "# input_chunks, target_chunks = tokenize_and_chunk(documents, labels)\n",
        "# # Convert labels to binary matrix\n",
        "# mlb = MultiLabelBinarizer()\n",
        "# binarized_labels = mlb.fit_transform(target_chunks)\n",
        "\n",
        "# # Convert input_chunks and binarized_labels to a Hugging Face Dataset\n",
        "# train_data = {\"input_ids\": input_chunks, \"labels\": binarized_labels.astype(float).tolist()}\n",
        "# train_dataset = Dataset.from_dict(train_data)\n",
        "\n",
        "\n",
        "\n",
        "# #-----------------TEST------------------------\n",
        "# # Convert test_df to Hugging Face Dataset\n",
        "# test_texts = test_df['text']\n",
        "# test_labels = test_df['narrative_labels']\n",
        "\n",
        "# # Tokenize and chunk the test dataset\n",
        "# test_chunks, test_targets = tokenize_and_chunk(test_texts, test_labels)\n",
        "# test_binarized_labels = mlb.transform(test_targets)\n",
        "\n",
        "# test_data = {\"input_ids\": test_chunks, \"labels\": test_binarized_labels.astype(float).tolist()}\n",
        "# test_dataset = Dataset.from_dict(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label multi-class classification"
      ],
      "metadata": {
        "id": "OxXhcommQ6so"
      },
      "id": "OxXhcommQ6so"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize tokenizer\n",
        "model_name = \"bert-base-multilingual-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_documents(documents, labels, max_length=512, tokenizer=None):\n",
        "    \"\"\"\n",
        "    Tokenizes documents into single sequences of max length `max_length`.\n",
        "    Adds [CLS] and [SEP] tokens automatically and pads/truncates to `max_length`.\n",
        "\n",
        "    Args:\n",
        "       documents (list): List of text documents to tokenize.\n",
        "       labels (list): List of labels corresponding to the documents.\n",
        "       max_length (int): Maximum length for tokenized sequences.\n",
        "       tokenizer (BertTokenizer): Pre-trained tokenizer instance.\n",
        "\n",
        "    Returns:\n",
        "       dict: Dictionary with `input_ids`, `attention_mask`, and `labels`.\n",
        "    \"\"\"\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "\n",
        "    for doc in documents:\n",
        "        # Tokenize and truncate/pad the document to `max_length`\n",
        "        tokens = tokenizer(\n",
        "            doc.lower(),\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids_list.append(tokens[\"input_ids\"].squeeze(0).tolist())\n",
        "        attention_mask_list.append(tokens[\"attention_mask\"].squeeze(0).tolist())\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids_list,\n",
        "        \"attention_mask\": attention_mask_list,\n",
        "        \"labels\": labels,\n",
        "    }\n",
        "\n",
        "# Ensure train_df and test_df are properly loaded Pandas DataFrames\n",
        "\n",
        "\n",
        "# ----------------- TRAIN -----------------------\n",
        "train_texts = train_df[\"text\"].tolist()  # Filter and convert column to list\n",
        "train_labels = train_df[\"sub_narrative_labels\"].tolist()  # Ensure labels are lists\n",
        "\n",
        "# MultiLabelBinarizer to binarize the labels\n",
        "mlb = MultiLabelBinarizer()\n",
        "train_binarized_labels = mlb.fit_transform(train_labels).astype(float).tolist()\n",
        "\n",
        "train_data = tokenize_documents(train_texts, train_binarized_labels, max_length=512, tokenizer=tokenizer)\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "\n",
        "# ----------------- TEST ------------------------\n",
        "test_texts = test_df[\"text\"].tolist()  # Filter and convert column to list\n",
        "test_labels = test_df[\"sub_narrative_labels\"].tolist()  # Ensure labels are lists\n",
        "\n",
        "test_binarized_labels = mlb.transform(test_labels).astype(float).tolist()  # Use same MultiLabelBinarizer\n",
        "\n",
        "test_data = tokenize_documents(test_texts, test_binarized_labels, max_length=512, tokenizer=tokenizer)\n",
        "test_dataset = Dataset.from_dict(test_data)\n",
        "\n",
        "# Example output to confirm functionality\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))\n",
        "print(\"Number of classes:\", mlb.classes_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "872fe0874c4c4118906264f0787e1bad",
            "822920dee9e2450da4e170aa6b2c8b8f",
            "552764a639c844c786ac9131a79ec5a2",
            "95f6bd41deec48458cbdee61b3dc2aa2",
            "1eef9a31c54445b1959cf835899f42de",
            "a9087caf3d10450e925ea95ac708a8ec",
            "43052c9e542d40519c42e09fc7255276",
            "af9915b9ab0246a1ba6a62cc34eac010",
            "570e5e86e13b4b178942a96be4b4413f",
            "48f867c6f07940a39ab5b74569600313",
            "41174a6d3dc64626af8bc2f27ea20659",
            "17db7dca69164cdc959a4dea187ccf21",
            "0f9c0eb3695846d6a3a63d84532ab6ec",
            "e1eaaafc0ecc4790ba73134af70acbbe",
            "fa5b73e1dd21407ab0abd4db00bfb40a",
            "0f80c2242cac4d1b893018ba10ceffb6",
            "caa7e90764c34841a982db0db27991e9",
            "58cda8985bd54d089ea5f97662c479c2",
            "a63b2f5ee9674597be5b9be0fa8b066e",
            "7ba8fd8233cb41df84ee8a7afbf3eb06",
            "350e86a0e1ad4b28b3f095a89c44d7ff",
            "c69aa2ffb3cc41f9a88e723f6b89b8fc",
            "fb9b027d3c644470a13bd5b576a236c8",
            "a1fc4e02704c45f88af96ab07c5f31be",
            "9adea2f0c72746869ee6795d5a4c98b6",
            "b9bec43a47084a208e5f61700afa8d8c",
            "40664c65a52345febd1c93f74805ee3d",
            "95558b9c191a4781b51cc1a56dc65ff7",
            "ca9278219fcd4529966162b04d2c4a9c",
            "91a417ba3d9b4e9e86572eefc6061c1e",
            "2b92f1ab151e467d92dc9bbeb7ec136f",
            "f3c65b57c22540da9a625120218b1d49",
            "2ad2b726b4a94c69b0e3907ae36c8eb7"
          ]
        },
        "id": "hxp_ReVggyA1",
        "outputId": "a95cd5fd-65d2-400d-c32d-3fce1085f352"
      },
      "id": "hxp_ReVggyA1",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "872fe0874c4c4118906264f0787e1bad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17db7dca69164cdc959a4dea187ccf21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb9b027d3c644470a13bd5b576a236c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['CC: Green policies are geopolitical instruments: Other'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 799\n",
            "Number of test samples: 76\n",
            "Number of classes: (92,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import BertForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, hamming_loss\n",
        "\n",
        "\n",
        "# Modify loss function to include class weights\n",
        "class WeightedBCEWithLogitsLoss(torch.nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super().__init__()\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "            logits, labels, pos_weight=self.weights\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "\n",
        "# Compute class weights\n",
        "flat_labels = np.concatenate(train_binarized_labels)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(flat_labels), y=flat_labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load pre-trained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=len(mlb.classes_)\n",
        ")\n",
        "model.config.problem_type = \"multi_label_classification\"\n",
        "model.criterion = WeightedBCEWithLogitsLoss(class_weights_tensor)\n",
        "\n",
        "\n",
        "# Metrics function\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    predictions = (torch.sigmoid(torch.tensor(logits)) > 0.5).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # Hamming loss\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "\n",
        "    # Precision, recall, and F1 (micro and macro averages)\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"micro\", zero_division=0\n",
        "    )\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    # Subset accuracy\n",
        "    subset_acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Classification report (as a string)\n",
        "    class_report = classification_report(labels, predictions, zero_division=0, target_names=mlb.classes_)\n",
        "\n",
        "    # Print the classification report\n",
        "    # print(\"\\nClassification Report:\")\n",
        "    # print(class_report)\n",
        "\n",
        "    return {\n",
        "        \"hamming_loss\": hamming,\n",
        "        \"micro_precision\": precision_micro,\n",
        "        \"micro_recall\": recall_micro,\n",
        "        \"micro_f1\": f1_micro,\n",
        "        \"macro_precision\": precision_macro,\n",
        "        \"macro_recall\": recall_macro,\n",
        "        \"macro_f1\": f1_macro,\n",
        "        \"subset_accuracy\": subset_acc,\n",
        "    }\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "EPOCHS = 50\n",
        "model_train_name = 'bert_classifier'\n",
        "learning_rate = 2e-5\n",
        "batch_size = 8\n",
        "\n",
        "# Define training arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"/content/drive/MyDrive/i2nlp_project/results/{model_train_name}\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    save_strategy=\"no\",  # Prevent saving every model\n",
        "    report_to=\"none\",\n",
        "    logging_dir=f\"/content/drive/MyDrive/i2nlp_project/logs/{model_train_name}\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "\n",
        "# Update Trainer with the validation dataset and metrics\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Evaluation results:\", results)\n"
      ],
      "metadata": {
        "id": "xJG5ouYagomv",
        "collapsed": true
      },
      "id": "xJG5ouYagomv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(f'/content/drive/MyDrive/i2nlp_project/models/bert_classifier_last/')\n",
        "tokenizer.save_pretrained(f'/content/drive/MyDrive/i2nlp_project/models/bert_classifier_last/')"
      ],
      "metadata": {
        "id": "SaPPGenO7D7R"
      },
      "id": "SaPPGenO7D7R",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    predictions = (torch.sigmoid(torch.tensor(logits)) > 0.5).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # Hamming loss\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "\n",
        "    # Precision, recall, and F1 (micro and macro averages)\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"micro\", zero_division=0\n",
        "    )\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    # Subset accuracy\n",
        "    subset_acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Classification report (as a string)\n",
        "    class_report = classification_report(labels, predictions, zero_division=0, target_names=mlb.classes_)\n",
        "\n",
        "    # Print the classification report\n",
        "    # print(\"\\nClassification Report:\")\n",
        "    # print(class_report)\n",
        "\n",
        "    return {\n",
        "        \"hamming_loss\": hamming,\n",
        "        \"micro_precision\": precision_micro,\n",
        "        \"micro_recall\": recall_micro,\n",
        "        \"micro_f1\": f1_micro,\n",
        "        \"macro_precision\": precision_macro,\n",
        "        \"macro_recall\": recall_macro,\n",
        "        \"macro_f1\": f1_macro,\n",
        "        \"subset_accuracy\": subset_acc,\n",
        "    }\n",
        "# Update Trainer with the validation dataset and metrics\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Evaluation results:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uCrOFPFEccZt",
        "outputId": "ae56d88d-7828-4428-febf-28d0de994e36"
      },
      "id": "uCrOFPFEccZt",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 31:45, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Subset Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.046400</td>\n",
              "      <td>0.086194</td>\n",
              "      <td>0.025887</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.248963</td>\n",
              "      <td>0.073887</td>\n",
              "      <td>0.039685</td>\n",
              "      <td>0.047817</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.105400</td>\n",
              "      <td>68.756000</td>\n",
              "      <td>9.047000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.053100</td>\n",
              "      <td>0.079978</td>\n",
              "      <td>0.025029</td>\n",
              "      <td>0.654545</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.291498</td>\n",
              "      <td>0.089883</td>\n",
              "      <td>0.055135</td>\n",
              "      <td>0.061991</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>1.154500</td>\n",
              "      <td>65.828000</td>\n",
              "      <td>8.662000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.049600</td>\n",
              "      <td>0.082012</td>\n",
              "      <td>0.025601</td>\n",
              "      <td>0.603175</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.298039</td>\n",
              "      <td>0.095411</td>\n",
              "      <td>0.072876</td>\n",
              "      <td>0.075037</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>67.855000</td>\n",
              "      <td>8.928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>0.081095</td>\n",
              "      <td>0.024886</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.292683</td>\n",
              "      <td>0.103649</td>\n",
              "      <td>0.055392</td>\n",
              "      <td>0.066023</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.141700</td>\n",
              "      <td>66.566000</td>\n",
              "      <td>8.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.049500</td>\n",
              "      <td>0.081854</td>\n",
              "      <td>0.025887</td>\n",
              "      <td>0.617021</td>\n",
              "      <td>0.151042</td>\n",
              "      <td>0.242678</td>\n",
              "      <td>0.063225</td>\n",
              "      <td>0.032115</td>\n",
              "      <td>0.039354</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.136600</td>\n",
              "      <td>66.864000</td>\n",
              "      <td>8.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.080720</td>\n",
              "      <td>0.025458</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.182292</td>\n",
              "      <td>0.282258</td>\n",
              "      <td>0.101329</td>\n",
              "      <td>0.060667</td>\n",
              "      <td>0.069014</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.132900</td>\n",
              "      <td>67.087000</td>\n",
              "      <td>8.827000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.037300</td>\n",
              "      <td>0.081030</td>\n",
              "      <td>0.025458</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.264463</td>\n",
              "      <td>0.103470</td>\n",
              "      <td>0.045689</td>\n",
              "      <td>0.058362</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.138200</td>\n",
              "      <td>66.770000</td>\n",
              "      <td>8.785000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>0.081267</td>\n",
              "      <td>0.025744</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.177083</td>\n",
              "      <td>0.274194</td>\n",
              "      <td>0.081896</td>\n",
              "      <td>0.048717</td>\n",
              "      <td>0.055680</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.137700</td>\n",
              "      <td>66.803000</td>\n",
              "      <td>8.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.039500</td>\n",
              "      <td>0.079276</td>\n",
              "      <td>0.025458</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.182292</td>\n",
              "      <td>0.282258</td>\n",
              "      <td>0.107583</td>\n",
              "      <td>0.061055</td>\n",
              "      <td>0.073301</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>1.132400</td>\n",
              "      <td>67.117000</td>\n",
              "      <td>8.831000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.032200</td>\n",
              "      <td>0.082274</td>\n",
              "      <td>0.026030</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.294574</td>\n",
              "      <td>0.091731</td>\n",
              "      <td>0.056437</td>\n",
              "      <td>0.064890</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>1.137100</td>\n",
              "      <td>66.839000</td>\n",
              "      <td>8.795000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.040600</td>\n",
              "      <td>0.082732</td>\n",
              "      <td>0.024886</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.314961</td>\n",
              "      <td>0.121291</td>\n",
              "      <td>0.064004</td>\n",
              "      <td>0.076696</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>1.140700</td>\n",
              "      <td>66.624000</td>\n",
              "      <td>8.766000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.084626</td>\n",
              "      <td>0.025601</td>\n",
              "      <td>0.614035</td>\n",
              "      <td>0.182292</td>\n",
              "      <td>0.281124</td>\n",
              "      <td>0.107428</td>\n",
              "      <td>0.056978</td>\n",
              "      <td>0.068942</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.141900</td>\n",
              "      <td>66.556000</td>\n",
              "      <td>8.757000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.085869</td>\n",
              "      <td>0.026602</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.300752</td>\n",
              "      <td>0.101972</td>\n",
              "      <td>0.082456</td>\n",
              "      <td>0.079703</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>1.138600</td>\n",
              "      <td>66.748000</td>\n",
              "      <td>8.783000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.030500</td>\n",
              "      <td>0.085007</td>\n",
              "      <td>0.026173</td>\n",
              "      <td>0.573770</td>\n",
              "      <td>0.182292</td>\n",
              "      <td>0.276680</td>\n",
              "      <td>0.085486</td>\n",
              "      <td>0.054145</td>\n",
              "      <td>0.062659</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.140800</td>\n",
              "      <td>66.618000</td>\n",
              "      <td>8.766000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.034500</td>\n",
              "      <td>0.083302</td>\n",
              "      <td>0.027031</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.286792</td>\n",
              "      <td>0.095113</td>\n",
              "      <td>0.071718</td>\n",
              "      <td>0.076762</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.143600</td>\n",
              "      <td>66.457000</td>\n",
              "      <td>8.744000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.025800</td>\n",
              "      <td>0.085811</td>\n",
              "      <td>0.025744</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.097150</td>\n",
              "      <td>0.060363</td>\n",
              "      <td>0.070476</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>1.136500</td>\n",
              "      <td>66.873000</td>\n",
              "      <td>8.799000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.030500</td>\n",
              "      <td>0.083868</td>\n",
              "      <td>0.026030</td>\n",
              "      <td>0.573529</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.101561</td>\n",
              "      <td>0.072192</td>\n",
              "      <td>0.076225</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.150900</td>\n",
              "      <td>66.033000</td>\n",
              "      <td>8.689000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.030300</td>\n",
              "      <td>0.084076</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.513158</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>0.291045</td>\n",
              "      <td>0.096101</td>\n",
              "      <td>0.059994</td>\n",
              "      <td>0.068190</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.139200</td>\n",
              "      <td>66.713000</td>\n",
              "      <td>8.778000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.027000</td>\n",
              "      <td>0.083449</td>\n",
              "      <td>0.026459</td>\n",
              "      <td>0.547945</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.301887</td>\n",
              "      <td>0.098741</td>\n",
              "      <td>0.066749</td>\n",
              "      <td>0.074787</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.142800</td>\n",
              "      <td>66.505000</td>\n",
              "      <td>8.751000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.029300</td>\n",
              "      <td>0.084439</td>\n",
              "      <td>0.027031</td>\n",
              "      <td>0.519481</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.297398</td>\n",
              "      <td>0.094290</td>\n",
              "      <td>0.073271</td>\n",
              "      <td>0.076613</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.137700</td>\n",
              "      <td>66.800000</td>\n",
              "      <td>8.789000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.025200</td>\n",
              "      <td>0.084589</td>\n",
              "      <td>0.026745</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.234375</td>\n",
              "      <td>0.324910</td>\n",
              "      <td>0.113053</td>\n",
              "      <td>0.102549</td>\n",
              "      <td>0.096800</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.138700</td>\n",
              "      <td>66.745000</td>\n",
              "      <td>8.782000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.026000</td>\n",
              "      <td>0.085581</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.557143</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>0.297710</td>\n",
              "      <td>0.098689</td>\n",
              "      <td>0.062944</td>\n",
              "      <td>0.072425</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.139700</td>\n",
              "      <td>66.686000</td>\n",
              "      <td>8.774000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.024100</td>\n",
              "      <td>0.084984</td>\n",
              "      <td>0.026459</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.312268</td>\n",
              "      <td>0.102393</td>\n",
              "      <td>0.076305</td>\n",
              "      <td>0.084325</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.148800</td>\n",
              "      <td>66.156000</td>\n",
              "      <td>8.705000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.023100</td>\n",
              "      <td>0.085265</td>\n",
              "      <td>0.027031</td>\n",
              "      <td>0.519481</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.297398</td>\n",
              "      <td>0.112470</td>\n",
              "      <td>0.061185</td>\n",
              "      <td>0.071656</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>1.148300</td>\n",
              "      <td>66.186000</td>\n",
              "      <td>8.709000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.021700</td>\n",
              "      <td>0.087267</td>\n",
              "      <td>0.026173</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.293436</td>\n",
              "      <td>0.095786</td>\n",
              "      <td>0.068379</td>\n",
              "      <td>0.073537</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.138200</td>\n",
              "      <td>66.772000</td>\n",
              "      <td>8.786000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.021800</td>\n",
              "      <td>0.087323</td>\n",
              "      <td>0.026602</td>\n",
              "      <td>0.542857</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.094394</td>\n",
              "      <td>0.060356</td>\n",
              "      <td>0.069886</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>1.140800</td>\n",
              "      <td>66.621000</td>\n",
              "      <td>8.766000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.087193</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.108937</td>\n",
              "      <td>0.064627</td>\n",
              "      <td>0.075243</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.145500</td>\n",
              "      <td>66.346000</td>\n",
              "      <td>8.730000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.016800</td>\n",
              "      <td>0.087959</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.098430</td>\n",
              "      <td>0.072235</td>\n",
              "      <td>0.077346</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.131600</td>\n",
              "      <td>67.162000</td>\n",
              "      <td>8.837000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.024200</td>\n",
              "      <td>0.088602</td>\n",
              "      <td>0.026459</td>\n",
              "      <td>0.544304</td>\n",
              "      <td>0.223958</td>\n",
              "      <td>0.317343</td>\n",
              "      <td>0.114104</td>\n",
              "      <td>0.070200</td>\n",
              "      <td>0.079261</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.147100</td>\n",
              "      <td>66.256000</td>\n",
              "      <td>8.718000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.022500</td>\n",
              "      <td>0.087931</td>\n",
              "      <td>0.026173</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.314607</td>\n",
              "      <td>0.107229</td>\n",
              "      <td>0.068379</td>\n",
              "      <td>0.079481</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.144300</td>\n",
              "      <td>66.417000</td>\n",
              "      <td>8.739000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.026300</td>\n",
              "      <td>0.090246</td>\n",
              "      <td>0.026745</td>\n",
              "      <td>0.532468</td>\n",
              "      <td>0.213542</td>\n",
              "      <td>0.304833</td>\n",
              "      <td>0.097986</td>\n",
              "      <td>0.063048</td>\n",
              "      <td>0.072657</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.138000</td>\n",
              "      <td>66.784000</td>\n",
              "      <td>8.787000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>0.086728</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.551282</td>\n",
              "      <td>0.223958</td>\n",
              "      <td>0.318519</td>\n",
              "      <td>0.125466</td>\n",
              "      <td>0.082917</td>\n",
              "      <td>0.094192</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.137300</td>\n",
              "      <td>66.827000</td>\n",
              "      <td>8.793000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.023000</td>\n",
              "      <td>0.089723</td>\n",
              "      <td>0.027460</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.283582</td>\n",
              "      <td>0.091935</td>\n",
              "      <td>0.058415</td>\n",
              "      <td>0.066873</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.146300</td>\n",
              "      <td>66.299000</td>\n",
              "      <td>8.724000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>0.088331</td>\n",
              "      <td>0.027317</td>\n",
              "      <td>0.505882</td>\n",
              "      <td>0.223958</td>\n",
              "      <td>0.310469</td>\n",
              "      <td>0.098155</td>\n",
              "      <td>0.072365</td>\n",
              "      <td>0.080133</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.134600</td>\n",
              "      <td>66.981000</td>\n",
              "      <td>8.813000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.089891</td>\n",
              "      <td>0.027031</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.213542</td>\n",
              "      <td>0.302583</td>\n",
              "      <td>0.088518</td>\n",
              "      <td>0.063669</td>\n",
              "      <td>0.071622</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.136400</td>\n",
              "      <td>66.877000</td>\n",
              "      <td>8.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.089188</td>\n",
              "      <td>0.027031</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.229167</td>\n",
              "      <td>0.317690</td>\n",
              "      <td>0.130003</td>\n",
              "      <td>0.089635</td>\n",
              "      <td>0.101287</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.137000</td>\n",
              "      <td>66.843000</td>\n",
              "      <td>8.795000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.016700</td>\n",
              "      <td>0.090012</td>\n",
              "      <td>0.026888</td>\n",
              "      <td>0.525641</td>\n",
              "      <td>0.213542</td>\n",
              "      <td>0.303704</td>\n",
              "      <td>0.118539</td>\n",
              "      <td>0.076117</td>\n",
              "      <td>0.087436</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.135000</td>\n",
              "      <td>66.960000</td>\n",
              "      <td>8.810000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.021600</td>\n",
              "      <td>0.092371</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.513158</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>0.291045</td>\n",
              "      <td>0.102234</td>\n",
              "      <td>0.068379</td>\n",
              "      <td>0.077053</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.146000</td>\n",
              "      <td>66.316000</td>\n",
              "      <td>8.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.090209</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.512195</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.306569</td>\n",
              "      <td>0.116934</td>\n",
              "      <td>0.074901</td>\n",
              "      <td>0.084798</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.149000</td>\n",
              "      <td>66.147000</td>\n",
              "      <td>8.704000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.089290</td>\n",
              "      <td>0.026745</td>\n",
              "      <td>0.530864</td>\n",
              "      <td>0.223958</td>\n",
              "      <td>0.315018</td>\n",
              "      <td>0.110852</td>\n",
              "      <td>0.070605</td>\n",
              "      <td>0.080940</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.145900</td>\n",
              "      <td>66.323000</td>\n",
              "      <td>8.727000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.021800</td>\n",
              "      <td>0.089873</td>\n",
              "      <td>0.026459</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.229167</td>\n",
              "      <td>0.322344</td>\n",
              "      <td>0.107941</td>\n",
              "      <td>0.069508</td>\n",
              "      <td>0.080870</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.139500</td>\n",
              "      <td>66.697000</td>\n",
              "      <td>8.776000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>0.089914</td>\n",
              "      <td>0.026459</td>\n",
              "      <td>0.546667</td>\n",
              "      <td>0.213542</td>\n",
              "      <td>0.307116</td>\n",
              "      <td>0.107747</td>\n",
              "      <td>0.073814</td>\n",
              "      <td>0.083343</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.136500</td>\n",
              "      <td>66.874000</td>\n",
              "      <td>8.799000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.090561</td>\n",
              "      <td>0.026459</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.312268</td>\n",
              "      <td>0.107035</td>\n",
              "      <td>0.067215</td>\n",
              "      <td>0.077542</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.147100</td>\n",
              "      <td>66.253000</td>\n",
              "      <td>8.717000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.090152</td>\n",
              "      <td>0.027031</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.106065</td>\n",
              "      <td>0.066205</td>\n",
              "      <td>0.076516</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.146800</td>\n",
              "      <td>66.274000</td>\n",
              "      <td>8.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.020900</td>\n",
              "      <td>0.090919</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.095195</td>\n",
              "      <td>0.062944</td>\n",
              "      <td>0.071952</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.136900</td>\n",
              "      <td>66.850000</td>\n",
              "      <td>8.796000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.020300</td>\n",
              "      <td>0.090755</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.117478</td>\n",
              "      <td>0.074979</td>\n",
              "      <td>0.085817</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>1.137200</td>\n",
              "      <td>66.828000</td>\n",
              "      <td>8.793000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.021400</td>\n",
              "      <td>0.091178</td>\n",
              "      <td>0.027746</td>\n",
              "      <td>0.487179</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>0.281481</td>\n",
              "      <td>0.089760</td>\n",
              "      <td>0.057510</td>\n",
              "      <td>0.065793</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.137200</td>\n",
              "      <td>66.834000</td>\n",
              "      <td>8.794000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.016900</td>\n",
              "      <td>0.090983</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.095195</td>\n",
              "      <td>0.062944</td>\n",
              "      <td>0.071952</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.144000</td>\n",
              "      <td>66.436000</td>\n",
              "      <td>8.742000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.015800</td>\n",
              "      <td>0.090824</td>\n",
              "      <td>0.026745</td>\n",
              "      <td>0.531646</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.309963</td>\n",
              "      <td>0.106065</td>\n",
              "      <td>0.075988</td>\n",
              "      <td>0.085410</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.142700</td>\n",
              "      <td>66.507000</td>\n",
              "      <td>8.751000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.015800</td>\n",
              "      <td>0.090963</td>\n",
              "      <td>0.026888</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.308824</td>\n",
              "      <td>0.106065</td>\n",
              "      <td>0.075988</td>\n",
              "      <td>0.085410</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.138700</td>\n",
              "      <td>66.744000</td>\n",
              "      <td>8.782000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.09096293896436691, 'eval_hamming_loss': 0.02688787185354691, 'eval_micro_precision': 0.525, 'eval_micro_recall': 0.21875, 'eval_micro_f1': 0.3088235294117647, 'eval_macro_precision': 0.10606452726017944, 'eval_macro_recall': 0.0759879160694378, 'eval_macro_f1': 0.08540973840475792, 'eval_subset_accuracy': 0.15789473684210525, 'eval_runtime': 1.122, 'eval_samples_per_second': 67.735, 'eval_steps_per_second': 8.913, 'epoch': 50.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(eval_dataset=train_dataset)"
      ],
      "metadata": {
        "id": "Ar2EJYZvgoXU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b836772c-059f-40bc-e958-8247708d8bf5"
      },
      "id": "Ar2EJYZvgoXU",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='230' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 06:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                                                                                                                   precision    recall  f1-score   support\n",
            "\n",
            "                                        CC: Amplifying Climate Fears: Amplifying existing fears of global warming       1.00      1.00      1.00        35\n",
            "                                                      CC: Amplifying Climate Fears: Doomsday scenarios for humans       1.00      1.00      1.00        34\n",
            "                                                                              CC: Amplifying Climate Fears: Other       1.00      1.00      1.00        34\n",
            "                                                              CC: Climate change is beneficial: CO2 is beneficial       1.00      1.00      1.00        46\n",
            "                                             CC: Climate change is beneficial: Temperature increase is beneficial       1.00      1.00      1.00        34\n",
            "                                                                  CC: Controversy about green technologies: Other       1.00      1.00      1.00        81\n",
            "                                             CC: Controversy about green technologies: Renewable energy is costly       1.00      1.00      1.00        89\n",
            "                                          CC: Controversy about green technologies: Renewable energy is dangerous       1.00      1.00      1.00        39\n",
            "                                         CC: Controversy about green technologies: Renewable energy is unreliable       1.00      1.00      1.00        83\n",
            "                                           CC: Criticism of climate movement: Ad hominem attacks on key activists       1.00      1.00      1.00        99\n",
            "                                                  CC: Criticism of climate movement: Climate movement is alarmist       1.00      1.00      1.00       162\n",
            "                                                   CC: Criticism of climate movement: Climate movement is corrupt       1.00      1.00      1.00        63\n",
            "                                                                         CC: Criticism of climate movement: Other       1.00      1.00      1.00       115\n",
            "                                              CC: Criticism of climate policies: Climate policies are ineffective       1.00      1.00      1.00        78\n",
            "                                          CC: Criticism of climate policies: Climate policies are only for profit       1.00      1.00      1.00        75\n",
            "                          CC: Criticism of climate policies: Climate policies have negative impact on the economy       1.00      1.00      1.00       154\n",
            "                                                                         CC: Criticism of climate policies: Other       1.00      1.00      1.00        68\n",
            "                               CC: Criticism of institutions and authorities: Criticism of international entities       1.00      1.00      1.00        82\n",
            "                                 CC: Criticism of institutions and authorities: Criticism of national governments       1.00      1.00      1.00       255\n",
            "                  CC: Criticism of institutions and authorities: Criticism of political organizations and figures       1.00      1.00      1.00       220\n",
            "                                               CC: Criticism of institutions and authorities: Criticism of the EU       1.00      1.00      1.00        36\n",
            "                                                             CC: Criticism of institutions and authorities: Other       1.00      1.00      1.00        36\n",
            "                               CC: Downplaying climate change: CO2 concentrations are too small to have an impact       1.00      1.00      1.00        89\n",
            "                                                       CC: Downplaying climate change: Climate cycles are natural       1.00      1.00      1.00        77\n",
            "                                    CC: Downplaying climate change: Human activities do not impact climate change       1.00      1.00      1.00        52\n",
            "                                      CC: Downplaying climate change: Humans and nature will adapt to the changes       1.00      1.00      1.00        34\n",
            "                                                               CC: Downplaying climate change: Ice is not melting       1.00      1.00      1.00        34\n",
            "                                                                            CC: Downplaying climate change: Other       1.00      1.00      1.00       108\n",
            "                                                        CC: Downplaying climate change: Sea levels are not rising       1.00      1.00      1.00        34\n",
            "                            CC: Downplaying climate change: Temperature increase does not have significant impact       1.00      1.00      1.00        51\n",
            "                                     CC: Downplaying climate change: Weather suggests the trend is global cooling       1.00      1.00      1.00        34\n",
            "CC: Green policies are geopolitical instruments: Climate-related international relations are abusive/exploitative       1.00      1.00      1.00        51\n",
            "                  CC: Green policies are geopolitical instruments: Green activities are a form of neo-colonialism       1.00      1.00      1.00        41\n",
            "                                     CC: Hidden plots by secret schemes of powerful groups: Blaming global elites       1.00      1.00      1.00       114\n",
            "                         CC: Hidden plots by secret schemes of powerful groups: Climate agenda has hidden motives       1.00      1.00      1.00       202\n",
            "                                                     CC: Hidden plots by secret schemes of powerful groups: Other       1.00      1.00      1.00        51\n",
            "                                 CC: Questioning the measurements and science: Data shows no temperature increase       1.00      1.00      1.00        34\n",
            "       CC: Questioning the measurements and science: Greenhouse effect/carbon dioxide do not drive climate change       1.00      1.00      1.00        34\n",
            "                   CC: Questioning the measurements and science: Methodologies/metrics used are unreliable/faulty       1.00      1.00      1.00       156\n",
            "                                                              CC: Questioning the measurements and science: Other       1.00      1.00      1.00        72\n",
            "                                 CC: Questioning the measurements and science: Scientific community is unreliable       1.00      1.00      1.00       182\n",
            "                                                                                                            Other       1.00      1.00      1.00       169\n",
            "                                           URW: Amplifying war-related fears: By continuing the war we risk WWIII       1.00      1.00      1.00        96\n",
            "                                           URW: Amplifying war-related fears: NATO should/will directly intervene       1.00      1.00      1.00        47\n",
            "                                                                         URW: Amplifying war-related fears: Other       1.00      1.00      1.00        43\n",
            "                                       URW: Amplifying war-related fears: Russia will also attack other countries       1.00      1.00      1.00        59\n",
            "             URW: Amplifying war-related fears: There is a real possibility that nuclear weapons will be employed       1.00      1.00      1.00       126\n",
            "                              URW: Blaming the war on others rather than the invader: The West are the aggressors       1.00      1.00      1.00       193\n",
            "                                 URW: Blaming the war on others rather than the invader: Ukraine is the aggressor       1.00      1.00      1.00        60\n",
            "                          URW: Discrediting Ukraine: Discrediting Ukrainian government and officials and policies       1.00      1.00      1.00        89\n",
            "                                                       URW: Discrediting Ukraine: Discrediting Ukrainian military       1.00      1.00      1.00        43\n",
            "                                                           URW: Discrediting Ukraine: Rewriting Ukraine’s history       1.00      1.00      1.00        34\n",
            "                                                      URW: Discrediting Ukraine: Situation in Ukraine is hopeless       1.00      1.00      1.00        35\n",
            "                                              URW: Discrediting Ukraine: Ukraine is a hub for criminal activities       1.00      1.00      1.00        36\n",
            "                                                       URW: Discrediting Ukraine: Ukraine is a puppet of the West       1.00      1.00      1.00        79\n",
            "                                                     URW: Discrediting Ukraine: Ukraine is associated with nazism       1.00      1.00      1.00        65\n",
            "                                              URW: Discrediting the West, Diplomacy: Diplomacy does/will not work       1.00      1.00      1.00        74\n",
            "                                                                     URW: Discrediting the West, Diplomacy: Other       0.99      1.00      1.00       152\n",
            "                                                         URW: Discrediting the West, Diplomacy: The EU is divided       1.00      1.00      1.00        64\n",
            "            URW: Discrediting the West, Diplomacy: The West does not care about Ukraine, only about its interests       1.00      1.00      1.00        68\n",
            "                                                  URW: Discrediting the West, Diplomacy: The West is overreacting       1.00      1.00      1.00        41\n",
            "                                                          URW: Discrediting the West, Diplomacy: The West is weak       1.00      1.00      1.00        57\n",
            "                                                  URW: Discrediting the West, Diplomacy: West is tired of Ukraine       1.00      1.00      1.00        60\n",
            "                                                   URW: Distrust towards Media: Ukrainian media cannot be trusted       1.00      1.00      1.00        34\n",
            "                                        URW: Distrust towards Media: Western media is an instrument of propaganda       1.00      1.00      1.00       134\n",
            "                                                    URW: Hidden plots by secret schemes of powerful groups: Other       1.00      1.00      1.00        96\n",
            "                                                                   URW: Negative Consequences for the West: Other       1.00      1.00      1.00        39\n",
            "                    URW: Negative Consequences for the West: Sanctions imposed by Western countries will backfire       1.00      1.00      1.00        47\n",
            "        URW: Negative Consequences for the West: The conflict will increase the Ukrainian refugee flows to Europe       1.00      1.00      1.00        34\n",
            "                                        URW: Overpraising the West: The West belongs in the right side of history       1.00      1.00      1.00        51\n",
            "                                     URW: Overpraising the West: The West has the strongest international support       0.97      1.00      0.99        36\n",
            "                                                                                     URW: Praise of Russia: Other       1.00      1.00      1.00        34\n",
            "                                                URW: Praise of Russia: Praise of Russian President Vladimir Putin       1.00      1.00      1.00        34\n",
            "                                                          URW: Praise of Russia: Praise of Russian military might       1.00      1.00      1.00        60\n",
            "                    URW: Praise of Russia: Russia has international support from a number of countries and people       1.00      1.00      1.00        34\n",
            "                                             URW: Praise of Russia: Russia is a guarantor of peace and prosperity       1.00      1.00      1.00        36\n",
            "                                              URW: Praise of Russia: Russian invasion has strong national support       1.00      1.00      1.00        34\n",
            "                                                                                 URW: Russia is the Victim: Other       1.00      1.00      1.00        36\n",
            "                                       URW: Russia is the Victim: Russia actions in Ukraine are only self-defence       1.00      1.00      1.00        50\n",
            "                                                               URW: Russia is the Victim: The West is russophobic       1.00      1.00      1.00       103\n",
            "                                                              URW: Russia is the Victim: UA is anti-RU extremists       1.00      1.00      1.00        42\n",
            "                                                                             URW: Speculating war outcomes: Other       1.00      1.00      1.00        64\n",
            "                                                        URW: Speculating war outcomes: Russian army is collapsing       1.00      1.00      1.00        36\n",
            "                                                      URW: Speculating war outcomes: Ukrainian army is collapsing       1.00      1.00      1.00        49\n",
            "\n",
            "                                                                                                        micro avg       1.00      1.00      1.00      6141\n",
            "                                                                                                        macro avg       1.00      1.00      1.00      6141\n",
            "                                                                                                     weighted avg       1.00      1.00      1.00      6141\n",
            "                                                                                                      samples avg       1.00      1.00      1.00      6141\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.007371334359049797,\n",
              " 'eval_hamming_loss': 1.3316288484073719e-05,\n",
              " 'eval_micro_precision': 0.9996744261761354,\n",
              " 'eval_micro_recall': 1.0,\n",
              " 'eval_micro_f1': 0.9998371865841745,\n",
              " 'eval_macro_precision': 0.9996004407769112,\n",
              " 'eval_macro_recall': 1.0,\n",
              " 'eval_macro_f1': 0.9997978890635527,\n",
              " 'eval_subset_accuracy': 0.9994407158836689,\n",
              " 'eval_runtime': 25.7594,\n",
              " 'eval_samples_per_second': 69.411,\n",
              " 'eval_steps_per_second': 8.696,\n",
              " 'epoch': 50.0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(f'/content/drive/MyDrive/i2nlp_project/models/bert_512_augmented_en/')"
      ],
      "metadata": {
        "id": "PC-KxbATvhFU"
      },
      "id": "PC-KxbATvhFU",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "stGb6D4mybJB"
      },
      "id": "stGb6D4mybJB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the model and tokenizer from the saved path\n",
        "model_path = '/content/drive/MyDrive/i2nlp_project/models/bert_classifier_last/'\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3X-TYw-PXec",
        "outputId": "b34d664c-c66e-4b30-b7e3-9feaead5bc4f"
      },
      "id": "M3X-TYw-PXec",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=92, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for test set (optional, for batch processing)\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, hamming_loss\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.tensor([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.tensor([item['attention_mask'] for item in batch])\n",
        "    labels = torch.tensor([item['labels'] for item in batch], dtype=torch.float)  # Use float for multi-label\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "\n",
        "# Create DataLoader for the test set\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
        "\n",
        "# Collect predictions and labels for evaluation\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "\n",
        "# Loop through test set and get predictions\n",
        "for batch in test_loader:\n",
        "    inputs = {\n",
        "        \"input_ids\": batch[\"input_ids\"],\n",
        "        \"attention_mask\": batch[\"attention_mask\"]\n",
        "    }\n",
        "    labels = batch[\"labels\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        all_logits.append(logits)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "# Convert logits and labels into tensors and concatenate\n",
        "all_logits = torch.cat(all_logits, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n"
      ],
      "metadata": {
        "id": "_kGq-ILeQCMA"
      },
      "id": "_kGq-ILeQCMA",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    predictions = (torch.sigmoid(torch.tensor(logits)) > 0.3).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # Hamming loss\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "\n",
        "    # Precision, recall, and F1 (micro and macro averages)\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"micro\", zero_division=0\n",
        "    )\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    # Subset accuracy\n",
        "    subset_acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Classification report (as a string)\n",
        "    class_report = classification_report(labels, predictions, zero_division=0, target_names=mlb.classes_)\n",
        "\n",
        "    # Print the classification report\n",
        "    # print(\"\\nClassification Report:\")\n",
        "    # print(class_report)\n",
        "\n",
        "    return {\n",
        "        \"hamming_loss\": hamming,\n",
        "        \"micro_precision\": precision_micro,\n",
        "        \"micro_recall\": recall_micro,\n",
        "        \"micro_f1\": f1_micro,\n",
        "        \"macro_precision\": precision_macro,\n",
        "        \"macro_recall\": recall_macro,\n",
        "        \"macro_f1\": f1_macro,\n",
        "        \"subset_accuracy\": subset_acc,\n",
        "    }\n",
        "\n",
        "# Compute the metrics using the logits and labels\n",
        "metrics = compute_metrics((all_logits.numpy(), all_labels.numpy()))\n",
        "\n",
        "# Print the results\n",
        "print(\"Computed Metrics:\")\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMJuxruhVFG4",
        "outputId": "10677790-d205-4df9-8c1d-5670e24d86b2"
      },
      "id": "XMJuxruhVFG4",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Metrics:\n",
            "hamming_loss: 0.02917620137299771\n",
            "micro_precision: 0.45384615384615384\n",
            "micro_recall: 0.3072916666666667\n",
            "micro_f1: 0.36645962732919257\n",
            "macro_precision: 0.14227732126759585\n",
            "macro_recall: 0.14807941153049847\n",
            "macro_f1: 0.13162103334598607\n",
            "subset_accuracy: 0.15789473684210525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16JF-jQcamF3"
      },
      "id": "16JF-jQcamF3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (torch.sigmoid(all_logits) > 0.3).int().numpy()\n",
        "result_df_save = test_df[['filename', 'language']] # , 'narrative', 'sub_narrative'\n",
        "# result_df_save['predicted_labels'] = mlb.inverse_transform(predictions)\n",
        "result_df_save['narrative'] = [';'.join(list(set(':'.join(j.split(':')[:2]) for j in i))) if i else 'Other' for i in mlb.inverse_transform(predictions)]\n",
        "result_df_save['sub_narrative'] = [';'.join(i if i else ['Other']) for i in mlb.inverse_transform(predictions)]\n",
        "# result_df_save.to_csv('/content/drive/MyDrive/i2nlp_project/predicted/bert_en_25.csv', index=False, sep='\\t', header=None)\n",
        "result_df_save[result_df_save['language'] == 'EN'][['filename', 'narrative', 'sub_narrative']]\\\n",
        ".to_csv('/content/drive/MyDrive/i2nlp_project/predicted/dev_bert_en_25.txt', index=False, sep='\\t', header=None)\n",
        "result_df_save[result_df_save['language'] == 'PT'][['filename', 'narrative', 'sub_narrative']]\\\n",
        ".to_csv('/content/drive/MyDrive/i2nlp_project/predicted/dev_bert_pt_25.txt', index=False, sep='\\t', header=None)\n",
        "result_df_save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "W8vVuLJdXXNe",
        "outputId": "c02289b8-a910-4f75-dcf2-94e5747d4da8"
      },
      "id": "W8vVuLJdXXNe",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-6b5aa35e0221>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  result_df_save['narrative'] = [';'.join(list(set(':'.join(j.split(':')[:2]) for j in i))) if i else 'Other' for i in mlb.inverse_transform(predictions)]\n",
            "<ipython-input-48-6b5aa35e0221>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  result_df_save['sub_narrative'] = [';'.join(i if i else ['Other']) for i in mlb.inverse_transform(predictions)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                filename language  \\\n",
              "0   EN_UA_DEV_100012.txt       EN   \n",
              "1       EN_CC_200053.txt       EN   \n",
              "2       EN_CC_200040.txt       EN   \n",
              "3       EN_CC_200070.txt       EN   \n",
              "4   EN_UA_DEV_100034.txt       EN   \n",
              "..                   ...      ...   \n",
              "71            PT_207.txt       PT   \n",
              "72            PT_217.txt       PT   \n",
              "73            PT_204.txt       PT   \n",
              "74            PT_229.txt       PT   \n",
              "75            PT_225.txt       PT   \n",
              "\n",
              "                                            narrative  \\\n",
              "0                                               Other   \n",
              "1       CC: Criticism of institutions and authorities   \n",
              "2   CC: Criticism of climate movement;CC: Criticis...   \n",
              "3                                               Other   \n",
              "4   URW: Discrediting the West, Diplomacy;URW: Dis...   \n",
              "..                                                ...   \n",
              "71                  CC: Criticism of climate policies   \n",
              "72                       CC: Amplifying Climate Fears   \n",
              "73      CC: Criticism of institutions and authorities   \n",
              "74                       CC: Amplifying Climate Fears   \n",
              "75  CC: Criticism of institutions and authorities;...   \n",
              "\n",
              "                                        sub_narrative  \n",
              "0                                               Other  \n",
              "1   CC: Criticism of institutions and authorities:...  \n",
              "2   CC: Criticism of climate movement: Climate mov...  \n",
              "3                                               Other  \n",
              "4   URW: Discrediting Ukraine: Discrediting Ukrain...  \n",
              "..                                                ...  \n",
              "71           CC: Criticism of climate policies: Other  \n",
              "72  CC: Amplifying Climate Fears: Amplifying exist...  \n",
              "73  CC: Criticism of institutions and authorities:...  \n",
              "74                CC: Amplifying Climate Fears: Other  \n",
              "75  CC: Amplifying Climate Fears: Other;CC: Critic...  \n",
              "\n",
              "[76 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c592f936-bced-49db-b4f0-4ebd656ee30a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>language</th>\n",
              "      <th>narrative</th>\n",
              "      <th>sub_narrative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EN_UA_DEV_100012.txt</td>\n",
              "      <td>EN</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EN_CC_200053.txt</td>\n",
              "      <td>EN</td>\n",
              "      <td>CC: Criticism of institutions and authorities</td>\n",
              "      <td>CC: Criticism of institutions and authorities:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EN_CC_200040.txt</td>\n",
              "      <td>EN</td>\n",
              "      <td>CC: Criticism of climate movement;CC: Criticis...</td>\n",
              "      <td>CC: Criticism of climate movement: Climate mov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EN_CC_200070.txt</td>\n",
              "      <td>EN</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EN_UA_DEV_100034.txt</td>\n",
              "      <td>EN</td>\n",
              "      <td>URW: Discrediting the West, Diplomacy;URW: Dis...</td>\n",
              "      <td>URW: Discrediting Ukraine: Discrediting Ukrain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>PT_207.txt</td>\n",
              "      <td>PT</td>\n",
              "      <td>CC: Criticism of climate policies</td>\n",
              "      <td>CC: Criticism of climate policies: Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>PT_217.txt</td>\n",
              "      <td>PT</td>\n",
              "      <td>CC: Amplifying Climate Fears</td>\n",
              "      <td>CC: Amplifying Climate Fears: Amplifying exist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>PT_204.txt</td>\n",
              "      <td>PT</td>\n",
              "      <td>CC: Criticism of institutions and authorities</td>\n",
              "      <td>CC: Criticism of institutions and authorities:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>PT_229.txt</td>\n",
              "      <td>PT</td>\n",
              "      <td>CC: Amplifying Climate Fears</td>\n",
              "      <td>CC: Amplifying Climate Fears: Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>PT_225.txt</td>\n",
              "      <td>PT</td>\n",
              "      <td>CC: Criticism of institutions and authorities;...</td>\n",
              "      <td>CC: Amplifying Climate Fears: Other;CC: Critic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c592f936-bced-49db-b4f0-4ebd656ee30a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c592f936-bced-49db-b4f0-4ebd656ee30a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c592f936-bced-49db-b4f0-4ebd656ee30a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-191418f6-5359-4b9b-a4ac-f0d119267dcb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-191418f6-5359-4b9b-a4ac-f0d119267dcb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-191418f6-5359-4b9b-a4ac-f0d119267dcb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_95d88afa-aa8f-413d-ba72-add43aa67751\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df_save')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_95d88afa-aa8f-413d-ba72-add43aa67751 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df_save');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df_save",
              "summary": "{\n  \"name\": \"result_df_save\",\n  \"rows\": 76,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 76,\n        \"samples\": [\n          \"EN_UA_DEV_100034.txt\",\n          \"EN_CC_200030.txt\",\n          \"EN_UA_DEV_100029.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"PT\",\n          \"EN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"narrative\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"URW: Praise of Russia;URW: Blaming the war on others rather than the invader;URW: Russia is the Victim\",\n          \"URW: Blaming the war on others rather than the invader;URW: Hidden plots by secret schemes of powerful groups\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sub_narrative\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"URW: Discrediting the West, Diplomacy: Other;URW: Negative Consequences for the West: Other;URW: Negative Consequences for the West: Sanctions imposed by Western countries will backfire\",\n          \"CC: Criticism of institutions and authorities: Criticism of international entities;CC: Criticism of institutions and authorities: Criticism of national governments\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD CODE"
      ],
      "metadata": {
        "id": "flvF2HbngpTm"
      },
      "id": "flvF2HbngpTm"
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-multilingual-cased\"\n",
        "\n",
        "# Initialize tokenizer (example: multilingual cased)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_and_chunk(\n",
        "    documents,\n",
        "    labels,\n",
        "    chunk_size=512,\n",
        "    tokenizer=tokenizer\n",
        "):\n",
        "    \"\"\"\n",
        "    Tokenizes and chunks documents into segments of max length `chunk_size`.\n",
        "    Each chunk is prepended with [CLS] and appended with [SEP] tokens.\n",
        "\n",
        "    Returns:\n",
        "       input_ids_list: 2D list of token IDs (one sublist per chunk).\n",
        "       attention_mask_list: 2D list (same shape as input_ids_list).\n",
        "       labels_list: 1D list of labels aligned with the chunks.\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    # Subtract 2 to reserve space for [CLS] and [SEP]\n",
        "    effective_chunk_size = chunk_size - 2\n",
        "\n",
        "    for doc, label in zip(documents, labels):\n",
        "        # 1) Tokenize without adding special tokens or truncation\n",
        "        tokens = tokenizer(doc, add_special_tokens=False, truncation=False)\n",
        "        all_ids = tokens[\"input_ids\"]\n",
        "\n",
        "        # 2) Split the `all_ids` into chunks of `effective_chunk_size`\n",
        "        for i in range(0, len(all_ids), effective_chunk_size):\n",
        "            chunk_ids = all_ids[i : i + effective_chunk_size]\n",
        "\n",
        "            # Insert [CLS] and [SEP]\n",
        "            chunk_ids = [tokenizer.cls_token_id] + chunk_ids + [tokenizer.sep_token_id]\n",
        "\n",
        "            # Create attention mask (1 for real tokens, 0 for padding)\n",
        "            attention_mask = [1] * len(chunk_ids)\n",
        "\n",
        "            # 3) Pad up to `chunk_size` if needed\n",
        "            if len(chunk_ids) < chunk_size:\n",
        "                pad_length = chunk_size - len(chunk_ids)\n",
        "                chunk_ids += [tokenizer.pad_token_id] * pad_length\n",
        "                attention_mask += [0] * pad_length\n",
        "\n",
        "            # Collect results\n",
        "            input_ids_list.append(chunk_ids)\n",
        "            attention_mask_list.append(attention_mask)\n",
        "            labels_list.append(label)\n",
        "\n",
        "    return input_ids_list, attention_mask_list, labels_list\n",
        "\n",
        "\n",
        "# ----------------- TRAIN -----------------------\n",
        "documents = train_df[\"text\"]\n",
        "labels = train_df[\"dataset_type\"]\n",
        "\n",
        "input_chunks, attn_masks, target_chunks = tokenize_and_chunk(documents, labels, chunk_size=512)\n",
        "\n",
        "# Convert labels (e.g., multi-label) to binary matrix if needed\n",
        "mlb = MultiLabelBinarizer()\n",
        "binarized_labels = mlb.fit_transform(target_chunks)\n",
        "\n",
        "# Convert to a Hugging Face Dataset\n",
        "train_data = {\n",
        "    \"input_ids\": input_chunks,\n",
        "    \"attention_mask\": attn_masks,\n",
        "    \"labels\": binarized_labels.astype(float).tolist()\n",
        "}\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "\n",
        "# ----------------- TEST ------------------------\n",
        "test_texts = test_df[\"text\"]\n",
        "test_labels = test_df[\"dataset_type\"]\n",
        "\n",
        "test_chunks, test_attn_masks, test_targets = tokenize_and_chunk(test_texts, test_labels, chunk_size=512)\n",
        "test_binarized_labels = mlb.transform(test_targets)\n",
        "\n",
        "test_data = {\n",
        "    \"input_ids\": test_chunks,\n",
        "    \"attention_mask\": test_attn_masks,\n",
        "    \"labels\": test_binarized_labels.astype(float).tolist()\n",
        "}\n",
        "test_dataset = Dataset.from_dict(test_data)\n"
      ],
      "metadata": {
        "id": "Snbi5thdRu7b"
      },
      "id": "Snbi5thdRu7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify loss function to include class weights\n",
        "class WeightedBCEWithLogitsLoss(torch.nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super().__init__()\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "            logits, labels, pos_weight=self.weights\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "\n",
        "# Compute class weights\n",
        "flat_labels = np.concatenate(binarized_labels)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(flat_labels), y=flat_labels)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Load pre-trained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name, num_labels=len(mlb.classes_)\n",
        ")\n",
        "model.config.problem_type = \"multi_label_classification\"\n",
        "model.criterion = WeightedBCEWithLogitsLoss(class_weights_tensor)"
      ],
      "metadata": {
        "id": "ZzbIXrcwQ_-5"
      },
      "id": "ZzbIXrcwQ_-5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "\n",
        "EPOCHS = 10\n",
        "model_train_name = 'bert512_2025_01'\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"/content/drive/MyDrive/i2nlp_project/results/{model_train_name}\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    save_strategy=\"no\",  # Prevent saving every model\n",
        "    report_to=\"none\",\n",
        "    logging_dir=f\"/content/drive/MyDrive/i2nlp_project/logs/{model_train_name}\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "# Metrics function\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    predictions = (torch.sigmoid(torch.tensor(logits)) > 0.2).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    print(\"Logits:\\n\", logits[:3])\n",
        "    print(\"Sigmoid:\\n\", torch.sigmoid(torch.tensor(logits[:3])))\n",
        "    print(\"Predictions:\\n\", predictions[:3])\n",
        "    print(\"Labels:\\n\", labels[:3])\n",
        "\n",
        "    # Hamming loss\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "\n",
        "    # Precision, recall, and F1 (micro and macro averages)\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"micro\", zero_division=0\n",
        "    )\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    # Subset accuracy\n",
        "    subset_acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Classification report (as a string)\n",
        "    class_report = classification_report(labels, predictions, zero_division=0, target_names=mlb.classes_)\n",
        "\n",
        "    # Print the classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(class_report)\n",
        "\n",
        "    return {\n",
        "        \"hamming_loss\": hamming,\n",
        "        \"micro_precision\": precision_micro,\n",
        "        \"micro_recall\": recall_micro,\n",
        "        \"micro_f1\": f1_micro,\n",
        "        \"macro_precision\": precision_macro,\n",
        "        \"macro_recall\": recall_macro,\n",
        "        \"macro_f1\": f1_macro,\n",
        "        \"subset_accuracy\": subset_acc,\n",
        "    }\n",
        "\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)"
      ],
      "metadata": {
        "id": "Yf8GeHxnRFzA"
      },
      "id": "Yf8GeHxnRFzA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Update Trainer with validation dataset and metrics\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "# Train and evaluate\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Evaluation results:\", results)"
      ],
      "metadata": {
        "id": "iW0RbGT9RI-Q"
      },
      "id": "iW0RbGT9RI-Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(f'/content/drive/MyDrive/i2nlp_project/models/{model_train_name}/')"
      ],
      "metadata": {
        "id": "YU26Zdt7ROLK"
      },
      "id": "YU26Zdt7ROLK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(eval_dataset=train_dataset)\n",
        "results"
      ],
      "metadata": {
        "id": "8EfE7XkYRQX_"
      },
      "id": "8EfE7XkYRQX_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "flvF2HbngpTm"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3.9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "872fe0874c4c4118906264f0787e1bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_822920dee9e2450da4e170aa6b2c8b8f",
              "IPY_MODEL_552764a639c844c786ac9131a79ec5a2",
              "IPY_MODEL_95f6bd41deec48458cbdee61b3dc2aa2"
            ],
            "layout": "IPY_MODEL_1eef9a31c54445b1959cf835899f42de"
          }
        },
        "822920dee9e2450da4e170aa6b2c8b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9087caf3d10450e925ea95ac708a8ec",
            "placeholder": "​",
            "style": "IPY_MODEL_43052c9e542d40519c42e09fc7255276",
            "value": "vocab.txt: 100%"
          }
        },
        "552764a639c844c786ac9131a79ec5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9915b9ab0246a1ba6a62cc34eac010",
            "max": 871891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_570e5e86e13b4b178942a96be4b4413f",
            "value": 871891
          }
        },
        "95f6bd41deec48458cbdee61b3dc2aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48f867c6f07940a39ab5b74569600313",
            "placeholder": "​",
            "style": "IPY_MODEL_41174a6d3dc64626af8bc2f27ea20659",
            "value": " 872k/872k [00:01&lt;00:00, 768kB/s]"
          }
        },
        "1eef9a31c54445b1959cf835899f42de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9087caf3d10450e925ea95ac708a8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43052c9e542d40519c42e09fc7255276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9915b9ab0246a1ba6a62cc34eac010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570e5e86e13b4b178942a96be4b4413f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48f867c6f07940a39ab5b74569600313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41174a6d3dc64626af8bc2f27ea20659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17db7dca69164cdc959a4dea187ccf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f9c0eb3695846d6a3a63d84532ab6ec",
              "IPY_MODEL_e1eaaafc0ecc4790ba73134af70acbbe",
              "IPY_MODEL_fa5b73e1dd21407ab0abd4db00bfb40a"
            ],
            "layout": "IPY_MODEL_0f80c2242cac4d1b893018ba10ceffb6"
          }
        },
        "0f9c0eb3695846d6a3a63d84532ab6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caa7e90764c34841a982db0db27991e9",
            "placeholder": "​",
            "style": "IPY_MODEL_58cda8985bd54d089ea5f97662c479c2",
            "value": "tokenizer.json: 100%"
          }
        },
        "e1eaaafc0ecc4790ba73134af70acbbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63b2f5ee9674597be5b9be0fa8b066e",
            "max": 1715180,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ba8fd8233cb41df84ee8a7afbf3eb06",
            "value": 1715180
          }
        },
        "fa5b73e1dd21407ab0abd4db00bfb40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_350e86a0e1ad4b28b3f095a89c44d7ff",
            "placeholder": "​",
            "style": "IPY_MODEL_c69aa2ffb3cc41f9a88e723f6b89b8fc",
            "value": " 1.72M/1.72M [00:00&lt;00:00, 1.87MB/s]"
          }
        },
        "0f80c2242cac4d1b893018ba10ceffb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa7e90764c34841a982db0db27991e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58cda8985bd54d089ea5f97662c479c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a63b2f5ee9674597be5b9be0fa8b066e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba8fd8233cb41df84ee8a7afbf3eb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "350e86a0e1ad4b28b3f095a89c44d7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69aa2ffb3cc41f9a88e723f6b89b8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb9b027d3c644470a13bd5b576a236c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1fc4e02704c45f88af96ab07c5f31be",
              "IPY_MODEL_9adea2f0c72746869ee6795d5a4c98b6",
              "IPY_MODEL_b9bec43a47084a208e5f61700afa8d8c"
            ],
            "layout": "IPY_MODEL_40664c65a52345febd1c93f74805ee3d"
          }
        },
        "a1fc4e02704c45f88af96ab07c5f31be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95558b9c191a4781b51cc1a56dc65ff7",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9278219fcd4529966162b04d2c4a9c",
            "value": "config.json: 100%"
          }
        },
        "9adea2f0c72746869ee6795d5a4c98b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a417ba3d9b4e9e86572eefc6061c1e",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b92f1ab151e467d92dc9bbeb7ec136f",
            "value": 625
          }
        },
        "b9bec43a47084a208e5f61700afa8d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c65b57c22540da9a625120218b1d49",
            "placeholder": "​",
            "style": "IPY_MODEL_2ad2b726b4a94c69b0e3907ae36c8eb7",
            "value": " 625/625 [00:00&lt;00:00, 57.3kB/s]"
          }
        },
        "40664c65a52345febd1c93f74805ee3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95558b9c191a4781b51cc1a56dc65ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9278219fcd4529966162b04d2c4a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91a417ba3d9b4e9e86572eefc6061c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b92f1ab151e467d92dc9bbeb7ec136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3c65b57c22540da9a625120218b1d49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad2b726b4a94c69b0e3907ae36c8eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}