{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "606227292e7ac094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:06:53.166313Z",
     "start_time": "2025-01-22T21:06:53.094199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>narrative</th>\n",
       "      <th>sub_narrative</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>narrative_labels</th>\n",
       "      <th>sub_narrative_labels</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN_CC_100013.txt</td>\n",
       "      <td>CC: Criticism of climate movement</td>\n",
       "      <td>CC: Criticism of climate movement: Ad hominem ...</td>\n",
       "      <td>Bill Gates Says He Is ‘The Solution’ To Climat...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['CC: Criticism of climate movement']</td>\n",
       "      <td>['CC: Criticism of climate movement: Ad homine...</td>\n",
       "      <td>bill gates say solution climate change ok priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN_UA_300009.txt</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Russia: Clashes erupt in Bashkortostan as righ...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>russia clash erupt bashkortostan right activis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN_UA_300017.txt</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>McDonald's to exit Russia, sell business in co...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>mcdonald exit russia sell business country ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN_CC_100021.txt</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Collaborative plans, innovation keys to circul...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>collaborative plan innovation key circular rmg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN_UA_300041.txt</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Russia intends to supply light ‘Mountain’ tank...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>russia intend supply light mountain tank infan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>PT_207.txt</td>\n",
       "      <td>CC: Criticism of institutions and authorities;...</td>\n",
       "      <td>CC: Criticism of institutions and authorities:...</td>\n",
       "      <td>Zequinha critica UE por adiar obrigatoriedade ...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>zequinha critico ue adiar obrigatoriedade pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>PT_217.txt</td>\n",
       "      <td>CC: Amplifying Climate Fears;CC: Amplifying Cl...</td>\n",
       "      <td>CC: Amplifying Climate Fears: Other;CC: Amplif...</td>\n",
       "      <td>O que é a cúpula de calor? Entenda fenómeno qu...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Amplifying Climate Fears', 'CC: Amplifyi...</td>\n",
       "      <td>['CC: Amplifying Climate Fears: Other', 'CC: A...</td>\n",
       "      <td>cúpula calor entenda fenómeno prender ar quent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>PT_204.txt</td>\n",
       "      <td>CC: Amplifying Climate Fears;CC: Amplifying Cl...</td>\n",
       "      <td>CC: Amplifying Climate Fears: Amplifying exist...</td>\n",
       "      <td>COP28: Papa Francisco planeia participar nas n...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Amplifying Climate Fears', 'CC: Amplifyi...</td>\n",
       "      <td>['CC: Amplifying Climate Fears: Amplifying exi...</td>\n",
       "      <td>cop papa Francisco planear participar negociaç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>PT_229.txt</td>\n",
       "      <td>CC: Amplifying Climate Fears</td>\n",
       "      <td>CC: Amplifying Climate Fears: Amplifying exist...</td>\n",
       "      <td>Queda do tráfego pelo Canal do Panamá pode cus...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Amplifying Climate Fears']</td>\n",
       "      <td>['CC: Amplifying Climate Fears: Amplifying exi...</td>\n",
       "      <td>queda tráfego canal panamá custar milhão dólar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>PT_225.txt</td>\n",
       "      <td>CC: Criticism of institutions and authorities;...</td>\n",
       "      <td>CC: Criticism of institutions and authorities:...</td>\n",
       "      <td>Projetos no Congresso trarão danos irreversíve...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>projeto congresso trar dano irreversível ambie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename                                          narrative  \\\n",
       "0    EN_CC_100013.txt                  CC: Criticism of climate movement   \n",
       "1    EN_UA_300009.txt                                              Other   \n",
       "2    EN_UA_300017.txt                                              Other   \n",
       "3    EN_CC_100021.txt                                              Other   \n",
       "4    EN_UA_300041.txt                                              Other   \n",
       "..                ...                                                ...   \n",
       "870        PT_207.txt  CC: Criticism of institutions and authorities;...   \n",
       "871        PT_217.txt  CC: Amplifying Climate Fears;CC: Amplifying Cl...   \n",
       "872        PT_204.txt  CC: Amplifying Climate Fears;CC: Amplifying Cl...   \n",
       "873        PT_229.txt                       CC: Amplifying Climate Fears   \n",
       "874        PT_225.txt  CC: Criticism of institutions and authorities;...   \n",
       "\n",
       "                                         sub_narrative  \\\n",
       "0    CC: Criticism of climate movement: Ad hominem ...   \n",
       "1                                                Other   \n",
       "2                                                Other   \n",
       "3                                                Other   \n",
       "4                                                Other   \n",
       "..                                                 ...   \n",
       "870  CC: Criticism of institutions and authorities:...   \n",
       "871  CC: Amplifying Climate Fears: Other;CC: Amplif...   \n",
       "872  CC: Amplifying Climate Fears: Amplifying exist...   \n",
       "873  CC: Amplifying Climate Fears: Amplifying exist...   \n",
       "874  CC: Criticism of institutions and authorities:...   \n",
       "\n",
       "                                                  text language  \\\n",
       "0    Bill Gates Says He Is ‘The Solution’ To Climat...       EN   \n",
       "1    Russia: Clashes erupt in Bashkortostan as righ...       EN   \n",
       "2    McDonald's to exit Russia, sell business in co...       EN   \n",
       "3    Collaborative plans, innovation keys to circul...       EN   \n",
       "4    Russia intends to supply light ‘Mountain’ tank...       EN   \n",
       "..                                                 ...      ...   \n",
       "870  Zequinha critica UE por adiar obrigatoriedade ...       PT   \n",
       "871  O que é a cúpula de calor? Entenda fenómeno qu...       PT   \n",
       "872  COP28: Papa Francisco planeia participar nas n...       PT   \n",
       "873  Queda do tráfego pelo Canal do Panamá pode cus...       PT   \n",
       "874  Projetos no Congresso trarão danos irreversíve...       PT   \n",
       "\n",
       "                                      narrative_labels  \\\n",
       "0                ['CC: Criticism of climate movement']   \n",
       "1                                            ['Other']   \n",
       "2                                            ['Other']   \n",
       "3                                            ['Other']   \n",
       "4                                            ['Other']   \n",
       "..                                                 ...   \n",
       "870  ['CC: Criticism of institutions and authoritie...   \n",
       "871  ['CC: Amplifying Climate Fears', 'CC: Amplifyi...   \n",
       "872  ['CC: Amplifying Climate Fears', 'CC: Amplifyi...   \n",
       "873                   ['CC: Amplifying Climate Fears']   \n",
       "874  ['CC: Criticism of institutions and authoritie...   \n",
       "\n",
       "                                  sub_narrative_labels  \\\n",
       "0    ['CC: Criticism of climate movement: Ad homine...   \n",
       "1                                            ['Other']   \n",
       "2                                            ['Other']   \n",
       "3                                            ['Other']   \n",
       "4                                            ['Other']   \n",
       "..                                                 ...   \n",
       "870  ['CC: Criticism of institutions and authoritie...   \n",
       "871  ['CC: Amplifying Climate Fears: Other', 'CC: A...   \n",
       "872  ['CC: Amplifying Climate Fears: Amplifying exi...   \n",
       "873  ['CC: Amplifying Climate Fears: Amplifying exi...   \n",
       "874  ['CC: Criticism of institutions and authoritie...   \n",
       "\n",
       "                                               cleaned  \n",
       "0    bill gates say solution climate change ok priv...  \n",
       "1    russia clash erupt bashkortostan right activis...  \n",
       "2    mcdonald exit russia sell business country ame...  \n",
       "3    collaborative plan innovation key circular rmg...  \n",
       "4    russia intend supply light mountain tank infan...  \n",
       "..                                                 ...  \n",
       "870  zequinha critico ue adiar obrigatoriedade pres...  \n",
       "871  cúpula calor entenda fenómeno prender ar quent...  \n",
       "872  cop papa Francisco planear participar negociaç...  \n",
       "873  queda tráfego canal panamá custar milhão dólar...  \n",
       "874  projeto congresso trar dano irreversível ambie...  \n",
       "\n",
       "[875 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load datasets\n",
    "training_data = pd.read_csv(\"training_data.csv\")\n",
    "target_data = pd.read_csv(\"target.csv\")\n",
    "\n",
    "# Concatenate the dataframes for later usage (axis=0)\n",
    "data = pd.concat([training_data, target_data], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "len_texts = [len(x) for x in data['cleaned']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923ffcdd9c29f262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:25.466360Z",
     "start_time": "2025-01-22T21:11:25.461426Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "# label mappings\n",
    "def build_vocab_and_labels(data):\n",
    "    word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    label_to_idx = {\"Other\": 0}\n",
    "    sublabel_to_idx = {\"Other\": 0}\n",
    "    language_to_idx = {\"EN\": 0, \"PT\": 1}\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # index the vocab\n",
    "        for word in tokenize(row[\"cleaned\"]):\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = len(word_to_idx)\n",
    "        # index the labels\n",
    "        for label in row[\"narrative\"].split(\";\"):\n",
    "            if label not in label_to_idx:\n",
    "                label_to_idx[label] = len(label_to_idx)\n",
    "        for sublabel in row[\"sub_narrative\"].split(\";\"):\n",
    "            if sublabel not in sublabel_to_idx:\n",
    "                sublabel_to_idx[sublabel] = len(sublabel_to_idx)\n",
    "\n",
    "    return word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d0abcb9e8de0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:26.181203Z",
     "start_time": "2025-01-22T21:11:26.054520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx = build_vocab_and_labels(data)\n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd7169851e7df37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:26.630190Z",
     "start_time": "2025-01-22T21:11:26.626593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fdc521ceee5493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:27.190062Z",
     "start_time": "2025-01-22T21:11:27.186395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(sublabel_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f932c06f6d034780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:27.853608Z",
     "start_time": "2025-01-22T21:11:27.846431Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, df, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx, max_len=50):\n",
    "        self.data = df\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.sublabel_to_idx = sublabel_to_idx\n",
    "        self.language_to_idx = language_to_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tokens = tokenize(row[\"text\"])\n",
    "        # assign the unk index if the word isn't indexed already\n",
    "        input_ids = [self.word_to_idx.get(word, self.word_to_idx[\"<UNK>\"]) for word in tokens]\n",
    "        # make sure the length is always 50 through padding if needed\n",
    "        input_ids = input_ids[:self.max_len] + [self.word_to_idx[\"<PAD>\"]] * (self.max_len - len(input_ids))\n",
    "\n",
    "        narrative_labels = [self.label_to_idx[label] for label in row[\"narrative\"].split(\";\")]\n",
    "        subnarrative_labels = [self.sublabel_to_idx[label] for label in row[\"sub_narrative\"].split(\";\")]\n",
    "\n",
    "        # Multi-label one-hot encoding\n",
    "        narrative_targets = torch.zeros(len(self.label_to_idx))\n",
    "        narrative_targets[narrative_labels] = 1\n",
    "\n",
    "        subnarrative_targets = torch.zeros(len(self.sublabel_to_idx))\n",
    "        subnarrative_targets[subnarrative_labels] = 1\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(self.language_to_idx[row[\"language\"]], dtype=torch.long),\n",
    "            narrative_targets,\n",
    "            subnarrative_targets\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84c47c4392463dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:29.897376Z",
     "start_time": "2025-01-22T21:11:29.893693Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = DocumentDataset(training_data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "val_dataset = DocumentDataset(target_data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e675f4b43e7db2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:30.470528Z",
     "start_time": "2025-01-22T21:11:30.465483Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM Model with an embedding layer and three classifiers in th end\n",
    "class LTSMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives):\n",
    "        super(LTSMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.lang_classifier = nn.Linear(hidden_dim, num_languages)\n",
    "        self.narrative_classifier = nn.Linear(hidden_dim, num_narratives)\n",
    "        self.subnarrative_classifier = nn.Linear(hidden_dim, num_subnarratives)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = hidden.squeeze(0)\n",
    "\n",
    "        lang_out = self.lang_classifier(hidden)\n",
    "        narrative_out = self.narrative_classifier(hidden)\n",
    "        subnarrative_out = self.subnarrative_classifier(hidden)\n",
    "\n",
    "        return lang_out, narrative_out, subnarrative_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3b50f54f36dc76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:31.285712Z",
     "start_time": "2025-01-22T21:11:31.209737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 30852213\n",
      "Trainable parameters: 30852213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "embed_dim = 1024\n",
    "hidden_dim = 1024\n",
    "num_languages = len(language_to_idx)\n",
    "num_narratives = len(label_to_idx)\n",
    "num_subnarratives = len(sublabel_to_idx)\n",
    "\n",
    "# the unweighted model to the gpu\n",
    "model_unweighted = LTSMModel(vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_unweighted.to(device)\n",
    "\n",
    "# the unweighted loss fucntions\n",
    "criterion_lang_unweighted = nn.CrossEntropyLoss()\n",
    "criterion_bce_unweighted = nn.BCEWithLogitsLoss()\n",
    "optimizer_unweighted = optim.Adam(model_unweighted.parameters(), lr=0.001)\n",
    "# Calculate the number of parameters\n",
    "total_params = sum(p.numel() for p in model_unweighted.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_unweighted.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f1936da3de8388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:12:06.897060Z",
     "start_time": "2025-01-22T21:11:34.352054Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "Train Loss: 0.8290\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 0.8561\n",
      "  Precision: 0.8566\n",
      "  Recall: 0.8561\n",
      "  F1-Score: 0.8560\n",
      "  Confusion Matrix:\n",
      "[[334  65]\n",
      " [ 50 350]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0697\n",
      "  Recall: 0.0187\n",
      "  F1-Score: 0.0262\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.1551\n",
      "  Recall: 0.0442\n",
      "  F1-Score: 0.0688\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0228\n",
      "  Recall: 0.0186\n",
      "  F1-Score: 0.0173\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.0476\n",
      "  Recall: 0.0435\n",
      "  F1-Score: 0.0455\n",
      "==================================================\n",
      "Epoch 201/201\n",
      "Train Loss: 0.0039\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[399   0]\n",
      " [  0 400]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.9832\n",
      "  Recall: 0.9866\n",
      "  F1-Score: 0.9849\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.9866\n",
      "  Recall: 0.9923\n",
      "  F1-Score: 0.9895\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.9778\n",
      "  Recall: 0.9791\n",
      "  F1-Score: 0.9784\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.9843\n",
      "  Recall: 0.9876\n",
      "  F1-Score: 0.9859\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 201\n",
    "for epoch in range(num_epochs):\n",
    "    model_unweighted.train()\n",
    "    train_loss = 0\n",
    "    all_lang_preds, all_lang_targets = [], []\n",
    "    all_narrative_preds, all_narrative_targets = [], []\n",
    "    all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "    for inputs, lang_targets, narrative_targets, subnarrative_targets in train_loader:\n",
    "        inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "            inputs.to(device),\n",
    "            lang_targets.to(device),\n",
    "            narrative_targets.to(device),\n",
    "            subnarrative_targets.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer_unweighted.zero_grad()\n",
    "        # forward pass\n",
    "        lang_out, narrative_out, subnarrative_out = model_unweighted(inputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss_lang = criterion_lang_unweighted(lang_out, lang_targets)\n",
    "        loss_narrative = criterion_bce_unweighted(narrative_out, narrative_targets)\n",
    "        loss_subnarrative = criterion_bce_unweighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "        loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "        loss.backward()\n",
    "        optimizer_unweighted.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # predictions\n",
    "        lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "        all_lang_preds.extend(lang_preds)\n",
    "        all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "        narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_narrative_preds.extend(narrative_preds)\n",
    "        all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "        subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_subnarrative_preds.extend(subnarrative_preds)\n",
    "        all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "    lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "    narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "    narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "    narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "    narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "    narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "    subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "    subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "    subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "    subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    # Log Epoch Results\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(\"\\nLanguage Classification Metrics:\")\n",
    "        print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "        print(f\"  Precision: {lang_precision:.4f}\")\n",
    "        print(f\"  Recall: {lang_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db148daed40f4d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:58:25.038016Z",
     "start_time": "2025-01-22T21:58:24.957590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8558\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[41  0]\n",
      " [ 0 35]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1711\n",
      "  Precision: 0.2330\n",
      "  Recall: 0.1061\n",
      "  F1-Score: 0.1343\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1711\n",
      "  Precision: 0.5088\n",
      "  Recall: 0.1973\n",
      "  F1-Score: 0.2843\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.0789\n",
      "  Precision: 0.0345\n",
      "  Recall: 0.0217\n",
      "  F1-Score: 0.0238\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.0789\n",
      "  Precision: 0.3023\n",
      "  Recall: 0.0674\n",
      "  F1-Score: 0.1102\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Validation Loop\n",
    "train_loss = 0\n",
    "all_lang_preds, all_lang_targets = [], []\n",
    "all_narrative_preds, all_narrative_targets = [], []\n",
    "all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "for inputs, lang_targets, narrative_targets, subnarrative_targets in val_loader:\n",
    "    inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "        inputs.to(device),\n",
    "        lang_targets.to(device),\n",
    "        narrative_targets.to(device),\n",
    "        subnarrative_targets.to(device),\n",
    "    )\n",
    "    # forward pass\n",
    "    lang_out, narrative_out, subnarrative_out = model_unweighted(inputs)\n",
    "\n",
    "    # Losses\n",
    "    loss_lang = criterion_lang_unweighted(lang_out, lang_targets)\n",
    "    loss_narrative = criterion_bce_unweighted(narrative_out, narrative_targets)\n",
    "    loss_subnarrative = criterion_bce_unweighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "    loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # predictions\n",
    "    lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "    all_lang_preds.extend(lang_preds)\n",
    "    all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "    narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_narrative_preds.extend(narrative_preds)\n",
    "    all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "    subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_subnarrative_preds.extend(subnarrative_preds)\n",
    "    all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "    \n",
    "#  Metrics\n",
    "lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "# Narrative Metrics\n",
    "narrative_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "narrative_micro_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Sub-Narrative Metrics\n",
    "subnarrative_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "subnarrative_micro_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Log Epoch Results\n",
    "print(f\"Validation Loss: {train_loss / len(val_loader):.4f}\")\n",
    "print(\"\\nLanguage Classification Metrics:\")\n",
    "print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lang_precision:.4f}\")\n",
    "print(f\"  Recall: {lang_recall:.4f}\")\n",
    "print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {narrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {narrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25faa9f7585b66b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:12:28.251255Z",
     "start_time": "2025-01-22T21:12:27.878020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21590/1170623561.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  narrative_targets = torch.stack([torch.tensor(target[2]) for target in all_dataset]).to(device)\n",
      "/tmp/ipykernel_21590/1170623561.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  subnarrative_targets = torch.stack([torch.tensor(target[3]) for target in all_dataset]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrative Class Weights: tensor([208.,  63.,  26.,  40., 129., 117.,  98.,  80., 171.,  14., 182.,  35.,\n",
      "         20., 138.,  25.,  52.,  25.,  44.,   8.,  78., 148.,   7.],\n",
      "       device='cuda:0')\n",
      "Subnarrative Class Weights: tensor([208.,  23.,  16.,  29.,  30.,   6.,  24.,  27.,  19.,  51.,  24.,  78.,\n",
      "         14.,  58.,  43.,  25.,  11., 127.,  38.,  35.,   1.,   2.,  13.,  10.,\n",
      "         42.,  30.,  42.,  19.,   3.,  21.,  25.,  15.,  73.,  13.,   9.,  13.,\n",
      "         11.,  11.,  27.,  18.,  51.,   2.,  76.,   6.,   5.,   5.,  14.,  31.,\n",
      "         38.,  35.,  10.,  18.,  11.,   3.,   6.,  82.,  31.,  15.,  13.,  15.,\n",
      "          8.,   3.,  32.,  25.,   3.,   4.,  24.,  20.,  18.,  28.,   1.,  38.,\n",
      "          2.,  69.,   9.,   3.,   2.,   1.,   5.,   8.,   2.,   3.,  28., 106.,\n",
      "         11.,   4.,  67.,   4.,   1.,   2.,   1.,   1.,   1.], device='cuda:0')\n",
      "Pos Weight for Narrative: tensor([ 1.0000,  3.3016,  8.0000,  5.2000,  1.6124,  1.7778,  2.1224,  2.6000,\n",
      "         1.2164, 14.8571,  1.1429,  5.9429, 10.4000,  1.5072,  8.3200,  4.0000,\n",
      "         8.3200,  4.7273, 26.0000,  2.6667,  1.4054, 29.7143], device='cuda:0')\n",
      "Pos Weight for Subnarrative: tensor([  1.0000,   9.0435,  13.0000,   7.1724,   6.9333,  34.6667,   8.6667,\n",
      "          7.7037,  10.9474,   4.0784,   8.6667,   2.6667,  14.8571,   3.5862,\n",
      "          4.8372,   8.3200,  18.9091,   1.6378,   5.4737,   5.9429, 208.0000,\n",
      "        104.0000,  16.0000,  20.8000,   4.9524,   6.9333,   4.9524,  10.9474,\n",
      "         69.3333,   9.9048,   8.3200,  13.8667,   2.8493,  16.0000,  23.1111,\n",
      "         16.0000,  18.9091,  18.9091,   7.7037,  11.5556,   4.0784, 104.0000,\n",
      "          2.7368,  34.6667,  41.6000,  41.6000,  14.8571,   6.7097,   5.4737,\n",
      "          5.9429,  20.8000,  11.5556,  18.9091,  69.3333,  34.6667,   2.5366,\n",
      "          6.7097,  13.8667,  16.0000,  13.8667,  26.0000,  69.3333,   6.5000,\n",
      "          8.3200,  69.3333,  52.0000,   8.6667,  10.4000,  11.5556,   7.4286,\n",
      "        208.0000,   5.4737, 104.0000,   3.0145,  23.1111,  69.3333, 104.0000,\n",
      "        208.0000,  41.6000,  26.0000, 104.0000,  69.3333,   7.4286,   1.9623,\n",
      "         18.9091,  52.0000,   3.1045,  52.0000, 208.0000, 104.0000, 208.0000,\n",
      "        208.0000, 208.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "all_dataset = DocumentDataset(data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "\n",
    "\n",
    "# get the labels\n",
    "narrative_targets = torch.stack([torch.tensor(target[2]) for target in all_dataset]).to(device)\n",
    "subnarrative_targets = torch.stack([torch.tensor(target[3]) for target in all_dataset]).to(device)\n",
    "\n",
    "# Compute the class weights for both narrative and sub_narrative\n",
    "narrative_class_weights = narrative_targets.sum(dim=0)  # Sum along rows (class-wise sum)\n",
    "subnarrative_class_weights = subnarrative_targets.sum(dim=0)  # Sum along rows (class-wise sum)\n",
    "\n",
    "# Normalize the class weights by dividing by the maximum class weight\n",
    "pos_weight_narrative = (narrative_class_weights.max() / narrative_class_weights).to(device)\n",
    "pos_weight_subnarrative = (subnarrative_class_weights.max() / subnarrative_class_weights).to(device)\n",
    "\n",
    "\n",
    "print(\"Narrative Class Weights:\", narrative_class_weights)\n",
    "print(\"Subnarrative Class Weights:\", subnarrative_class_weights)\n",
    "print(\"Pos Weight for Narrative:\", pos_weight_narrative)\n",
    "print(\"Pos Weight for Subnarrative:\", pos_weight_subnarrative)\n",
    "\n",
    "# update the loss functions\n",
    "criterion_narrative_weighted = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_narrative)\n",
    "criterion_subnarrative_weighted = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_subnarrative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e037072203bdfec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:26:09.301137Z",
     "start_time": "2025-01-23T14:25:39.606640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "Train Loss: 1.5537\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 0.8598\n",
      "  Precision: 0.8638\n",
      "  Recall: 0.8598\n",
      "  F1-Score: 0.8594\n",
      "  Confusion Matrix:\n",
      "[[322  77]\n",
      " [ 35 365]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.2330\n",
      "  Recall: 0.1061\n",
      "  F1-Score: 0.1343\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.5088\n",
      "  Recall: 0.1973\n",
      "  F1-Score: 0.2843\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0345\n",
      "  Recall: 0.0217\n",
      "  F1-Score: 0.0238\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.3023\n",
      "  Recall: 0.0674\n",
      "  F1-Score: 0.1102\n",
      "==================================================\n",
      "Epoch 201/201\n",
      "Train Loss: 0.0055\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[399   0]\n",
      " [  0 400]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.2330\n",
      "  Recall: 0.1061\n",
      "  F1-Score: 0.1343\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.5088\n",
      "  Recall: 0.1973\n",
      "  F1-Score: 0.2843\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0345\n",
      "  Recall: 0.0217\n",
      "  F1-Score: 0.0238\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.3023\n",
      "  Recall: 0.0674\n",
      "  F1-Score: 0.1102\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# weighted model\n",
    "model_weighted = LTSMModel(vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_weighted.to(device)\n",
    "\n",
    "criterion_lang_weighted = nn.CrossEntropyLoss()\n",
    "optimizer_weighted = optim.Adam(model_weighted.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 201\n",
    "for epoch in range(num_epochs):\n",
    "    model_weighted.train()\n",
    "    train_loss = 0\n",
    "    all_lang_preds, all_lang_targets = [], []\n",
    "    all_narrative_preds, all_narrative_targets = [], []\n",
    "    all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "    for inputs, lang_targets, narrative_targets, subnarrative_targets in train_loader:\n",
    "        inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "            inputs.to(device),\n",
    "            lang_targets.to(device),\n",
    "            narrative_targets.to(device),\n",
    "            subnarrative_targets.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer_weighted.zero_grad()\n",
    "        # forward pass\n",
    "        lang_out, narrative_out, subnarrative_out = model_weighted(inputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss_lang = criterion_lang_weighted(lang_out, lang_targets)\n",
    "        loss_narrative = criterion_narrative_weighted(narrative_out, narrative_targets)\n",
    "        loss_subnarrative = criterion_subnarrative_weighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "        loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "        loss.backward()\n",
    "        optimizer_weighted.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # predictions\n",
    "        lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "        all_lang_preds.extend(lang_preds)\n",
    "        all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "        narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_narrative_preds.extend(narrative_preds)\n",
    "        all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "        subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_subnarrative_preds.extend(subnarrative_preds)\n",
    "        all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "    #  Metrics\n",
    "    lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "    lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "    # Compute Metrics for Narrative (Multi-Label) Classification\n",
    "    narrative_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "    narrative_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "    narrative_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Compute Metrics for Sub-Narrative (Multi-Label) Classification\n",
    "    subnarrative_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "    subnarrative_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "    subnarrative_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Log Epoch Results\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(\"\\nLanguage Classification Metrics:\")\n",
    "        print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "        print(f\"  Precision: {lang_precision:.4f}\")\n",
    "        print(f\"  Recall: {lang_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd7a04d46a5efee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:59:07.063023Z",
     "start_time": "2025-01-22T21:59:07.000066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.8377\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[41  0]\n",
      " [ 0 35]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1974\n",
      "  Precision: 0.2928\n",
      "  Recall: 0.1488\n",
      "  F1-Score: 0.1815\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1974\n",
      "  Precision: 0.5373\n",
      "  Recall: 0.2449\n",
      "  F1-Score: 0.3364\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1053\n",
      "  Precision: 0.0625\n",
      "  Recall: 0.0385\n",
      "  F1-Score: 0.0415\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1053\n",
      "  Precision: 0.3774\n",
      "  Recall: 0.1036\n",
      "  F1-Score: 0.1626\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Validation Loop\n",
    "train_loss = 0\n",
    "all_lang_preds, all_lang_targets = [], []\n",
    "all_narrative_preds, all_narrative_targets = [], []\n",
    "all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "for inputs, lang_targets, narrative_targets, subnarrative_targets in val_loader:\n",
    "    inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "        inputs.to(device),\n",
    "        lang_targets.to(device),\n",
    "        narrative_targets.to(device),\n",
    "        subnarrative_targets.to(device),\n",
    "    )\n",
    "    # forward pass\n",
    "    lang_out, narrative_out, subnarrative_out = model_weighted(inputs)\n",
    "\n",
    "    # backward pass\n",
    "    loss_lang = criterion_lang_weighted(lang_out, lang_targets)\n",
    "    loss_narrative = criterion_narrative_weighted(narrative_out, narrative_targets)\n",
    "    loss_subnarrative = criterion_subnarrative_weighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "    loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # predictions\n",
    "    lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "    all_lang_preds.extend(lang_preds)\n",
    "    all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "    narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_narrative_preds.extend(narrative_preds)\n",
    "    all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "    subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_subnarrative_preds.extend(subnarrative_preds)\n",
    "    all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "#  Metrics\n",
    "lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "# Narrative Metrics\n",
    "narrative_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "narrative_micro_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Sub-Narrative Metrics\n",
    "subnarrative_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "subnarrative_micro_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Log Epoch Results\n",
    "print(f\"Validation Loss: {train_loss / len(val_loader):.4f}\")\n",
    "print(\"\\nLanguage Classification Metrics:\")\n",
    "print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lang_precision:.4f}\")\n",
    "print(f\"  Recall: {lang_recall:.4f}\")\n",
    "print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {narrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {narrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716a26ebdbf3249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T00:21:25.618340Z",
     "start_time": "2025-01-21T00:21:25.616573Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4051cfd3997418e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-2024.3",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
