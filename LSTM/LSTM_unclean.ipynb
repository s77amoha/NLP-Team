{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606227292e7ac094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:06:53.166313Z",
     "start_time": "2025-01-22T21:06:53.094199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8655"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load datasets\n",
    "training_data = pd.read_csv(\"training_data.csv\")\n",
    "target_data = pd.read_csv(\"target.csv\")\n",
    "\n",
    "# Concatenate the dataframes for later usage (axis=0)\n",
    "data = pd.concat([training_data, target_data], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "len_texts = [len(x) for x in data['text']]\n",
    "max(len_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923ffcdd9c29f262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:25.466360Z",
     "start_time": "2025-01-22T21:11:25.461426Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "# label mappings\n",
    "def build_vocab_and_labels(data):\n",
    "    word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    label_to_idx = {\"Other\": 0}\n",
    "    sublabel_to_idx = {\"Other\": 0}\n",
    "    language_to_idx = {\"EN\": 0, \"PT\": 1}\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # index the vocab\n",
    "        for word in tokenize(row[\"text\"]):\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = len(word_to_idx)\n",
    "        # index the labels\n",
    "        for label in row[\"narrative\"].split(\";\"):\n",
    "            if label not in label_to_idx:\n",
    "                label_to_idx[label] = len(label_to_idx)\n",
    "        for sublabel in row[\"sub_narrative\"].split(\";\"):\n",
    "            if sublabel not in sublabel_to_idx:\n",
    "                sublabel_to_idx[sublabel] = len(sublabel_to_idx)\n",
    "\n",
    "    return word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d0abcb9e8de0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:26.181203Z",
     "start_time": "2025-01-22T21:11:26.054520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51779"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx = build_vocab_and_labels(data)\n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd7169851e7df37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:26.630190Z",
     "start_time": "2025-01-22T21:11:26.626593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fdc521ceee5493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:27.190062Z",
     "start_time": "2025-01-22T21:11:27.186395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(sublabel_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f932c06f6d034780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:27.853608Z",
     "start_time": "2025-01-22T21:11:27.846431Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, df, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx, max_len=50):\n",
    "        self.data = df\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.sublabel_to_idx = sublabel_to_idx\n",
    "        self.language_to_idx = language_to_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tokens = tokenize(row[\"text\"])\n",
    "        # assign the unk index if the word isn't indexed already\n",
    "        input_ids = [self.word_to_idx.get(word, self.word_to_idx[\"<UNK>\"]) for word in tokens]\n",
    "        # make sure the length is always 50 through padding if needed\n",
    "        input_ids = input_ids[:self.max_len] + [self.word_to_idx[\"<PAD>\"]] * (self.max_len - len(input_ids))\n",
    "\n",
    "        narrative_labels = [self.label_to_idx[label] for label in row[\"narrative\"].split(\";\")]\n",
    "        subnarrative_labels = [self.sublabel_to_idx[label] for label in row[\"sub_narrative\"].split(\";\")]\n",
    "\n",
    "        # Multi-label one-hot encoding\n",
    "        narrative_targets = torch.zeros(len(self.label_to_idx))\n",
    "        narrative_targets[narrative_labels] = 1\n",
    "\n",
    "        subnarrative_targets = torch.zeros(len(self.sublabel_to_idx))\n",
    "        subnarrative_targets[subnarrative_labels] = 1\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(self.language_to_idx[row[\"language\"]], dtype=torch.long),\n",
    "            narrative_targets,\n",
    "            subnarrative_targets\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84c47c4392463dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:29.897376Z",
     "start_time": "2025-01-22T21:11:29.893693Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = DocumentDataset(training_data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "val_dataset = DocumentDataset(target_data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e675f4b43e7db2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:30.470528Z",
     "start_time": "2025-01-22T21:11:30.465483Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM Model with an embedding layer and three classifiers in th end\n",
    "class LTSMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives):\n",
    "        super(LTSMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.lang_classifier = nn.Linear(hidden_dim, num_languages)\n",
    "        self.narrative_classifier = nn.Linear(hidden_dim, num_narratives)\n",
    "        self.subnarrative_classifier = nn.Linear(hidden_dim, num_subnarratives)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = hidden.squeeze(0)\n",
    "\n",
    "        lang_out = self.lang_classifier(hidden)\n",
    "        narrative_out = self.narrative_classifier(hidden)\n",
    "        subnarrative_out = self.subnarrative_classifier(hidden)\n",
    "\n",
    "        return lang_out, narrative_out, subnarrative_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea3b50f54f36dc76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:31.285712Z",
     "start_time": "2025-01-22T21:11:31.209737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 61538421\n",
      "Trainable parameters: 61538421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "embed_dim = 1024\n",
    "hidden_dim = 1024\n",
    "num_languages = len(language_to_idx)\n",
    "num_narratives = len(label_to_idx)\n",
    "num_subnarratives = len(sublabel_to_idx)\n",
    "\n",
    "# the unweighted model to the gpu\n",
    "model_unweighted = LTSMModel(vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_unweighted.to(device)\n",
    "\n",
    "# the unweighted loss fucntions\n",
    "criterion_lang_unweighted = nn.CrossEntropyLoss()\n",
    "criterion_bce_unweighted = nn.BCEWithLogitsLoss()\n",
    "optimizer_unweighted = optim.Adam(model_unweighted.parameters(), lr=0.001)\n",
    "# Calculate the number of parameters\n",
    "total_params = sum(p.numel() for p in model_unweighted.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_unweighted.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7f1936da3de8388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:12:06.897060Z",
     "start_time": "2025-01-22T21:11:34.352054Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "Train Loss: 1.1416\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 0.8773\n",
      "  Precision: 0.8774\n",
      "  Recall: 0.8773\n",
      "  F1-Score: 0.8773\n",
      "  Confusion Matrix:\n",
      "[[352  47]\n",
      " [ 51 349]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.1106\n",
      "  Recall: 0.0838\n",
      "  F1-Score: 0.0854\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.1313\n",
      "  Recall: 0.1044\n",
      "  F1-Score: 0.1163\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0316\n",
      "  Recall: 0.0825\n",
      "  F1-Score: 0.0382\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.0364\n",
      "  Recall: 0.0989\n",
      "  F1-Score: 0.0532\n",
      "==================================================\n",
      "Epoch 201/201\n",
      "Train Loss: 0.0029\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[399   0]\n",
      " [  0 400]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.9865\n",
      "  Recall: 0.9887\n",
      "  F1-Score: 0.9876\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.9891\n",
      "  Recall: 0.9923\n",
      "  F1-Score: 0.9907\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.9795\n",
      "  Recall: 0.9810\n",
      "  F1-Score: 0.9802\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.9867\n",
      "  Recall: 0.9895\n",
      "  F1-Score: 0.9881\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 201\n",
    "for epoch in range(num_epochs):\n",
    "    model_unweighted.train()\n",
    "    train_loss = 0\n",
    "    all_lang_preds, all_lang_targets = [], []\n",
    "    all_narrative_preds, all_narrative_targets = [], []\n",
    "    all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "    for inputs, lang_targets, narrative_targets, subnarrative_targets in train_loader:\n",
    "        inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "            inputs.to(device),\n",
    "            lang_targets.to(device),\n",
    "            narrative_targets.to(device),\n",
    "            subnarrative_targets.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer_unweighted.zero_grad()\n",
    "        # forward pass\n",
    "        lang_out, narrative_out, subnarrative_out = model_unweighted(inputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss_lang = criterion_lang_unweighted(lang_out, lang_targets)\n",
    "        loss_narrative = criterion_bce_unweighted(narrative_out, narrative_targets)\n",
    "        loss_subnarrative = criterion_bce_unweighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "        loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "        loss.backward()\n",
    "        optimizer_unweighted.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # predictions\n",
    "        lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "        all_lang_preds.extend(lang_preds)\n",
    "        all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "        narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_narrative_preds.extend(narrative_preds)\n",
    "        all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "        subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_subnarrative_preds.extend(subnarrative_preds)\n",
    "        all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "    lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "    narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "    narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "    narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "    narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "    narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "    subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "    subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "    subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "    subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    # Log Epoch Results\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(\"\\nLanguage Classification Metrics:\")\n",
    "        print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "        print(f\"  Precision: {lang_precision:.4f}\")\n",
    "        print(f\"  Recall: {lang_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db148daed40f4d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:58:25.038016Z",
     "start_time": "2025-01-22T21:58:24.957590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1619\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[41  0]\n",
      " [ 0 35]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1316\n",
      "  Precision: 0.2203\n",
      "  Recall: 0.1121\n",
      "  F1-Score: 0.1279\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1316\n",
      "  Precision: 0.3472\n",
      "  Recall: 0.1701\n",
      "  F1-Score: 0.2283\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.0921\n",
      "  Precision: 0.0397\n",
      "  Recall: 0.0258\n",
      "  F1-Score: 0.0249\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.0921\n",
      "  Precision: 0.2800\n",
      "  Recall: 0.0725\n",
      "  F1-Score: 0.1152\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Validation Loop\n",
    "train_loss = 0\n",
    "all_lang_preds, all_lang_targets = [], []\n",
    "all_narrative_preds, all_narrative_targets = [], []\n",
    "all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "for inputs, lang_targets, narrative_targets, subnarrative_targets in val_loader:\n",
    "    inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "        inputs.to(device),\n",
    "        lang_targets.to(device),\n",
    "        narrative_targets.to(device),\n",
    "        subnarrative_targets.to(device),\n",
    "    )\n",
    "    # forward pass\n",
    "    lang_out, narrative_out, subnarrative_out = model_unweighted(inputs)\n",
    "\n",
    "    # Losses\n",
    "    loss_lang = criterion_lang_unweighted(lang_out, lang_targets)\n",
    "    loss_narrative = criterion_bce_unweighted(narrative_out, narrative_targets)\n",
    "    loss_subnarrative = criterion_bce_unweighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "    loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # predictions\n",
    "    lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "    all_lang_preds.extend(lang_preds)\n",
    "    all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "    narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_narrative_preds.extend(narrative_preds)\n",
    "    all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "    subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_subnarrative_preds.extend(subnarrative_preds)\n",
    "    all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "#  Metrics\n",
    "lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "# Narrative Metrics\n",
    "narrative_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "narrative_micro_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Sub-Narrative Metrics\n",
    "subnarrative_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "subnarrative_micro_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Log Epoch Results\n",
    "print(f\"Validation Loss: {train_loss / len(val_loader):.4f}\")\n",
    "print(\"\\nLanguage Classification Metrics:\")\n",
    "print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lang_precision:.4f}\")\n",
    "print(f\"  Recall: {lang_recall:.4f}\")\n",
    "print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {narrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {narrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25faa9f7585b66b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:12:28.251255Z",
     "start_time": "2025-01-22T21:12:27.878020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10690/1170623561.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  narrative_targets = torch.stack([torch.tensor(target[2]) for target in all_dataset]).to(device)\n",
      "/tmp/ipykernel_10690/1170623561.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  subnarrative_targets = torch.stack([torch.tensor(target[3]) for target in all_dataset]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrative Class Weights: tensor([208.,  63.,  26.,  40., 129., 117.,  98.,  80., 171.,  14., 182.,  35.,\n",
      "         20., 138.,  25.,  52.,  25.,  44.,   8.,  78., 148.,   7.],\n",
      "       device='cuda:0')\n",
      "Subnarrative Class Weights: tensor([208.,  23.,  16.,  29.,  30.,   6.,  24.,  27.,  19.,  51.,  24.,  78.,\n",
      "         14.,  58.,  43.,  25.,  11., 127.,  38.,  35.,   1.,   2.,  13.,  10.,\n",
      "         42.,  30.,  42.,  19.,   3.,  21.,  25.,  15.,  73.,  13.,   9.,  13.,\n",
      "         11.,  11.,  27.,  18.,  51.,   2.,  76.,   6.,   5.,   5.,  14.,  31.,\n",
      "         38.,  35.,  10.,  18.,  11.,   3.,   6.,  82.,  31.,  15.,  13.,  15.,\n",
      "          8.,   3.,  32.,  25.,   3.,   4.,  24.,  20.,  18.,  28.,   1.,  38.,\n",
      "          2.,  69.,   9.,   3.,   2.,   1.,   5.,   8.,   2.,   3.,  28., 106.,\n",
      "         11.,   4.,  67.,   4.,   1.,   2.,   1.,   1.,   1.], device='cuda:0')\n",
      "Pos Weight for Narrative: tensor([ 1.0000,  3.3016,  8.0000,  5.2000,  1.6124,  1.7778,  2.1224,  2.6000,\n",
      "         1.2164, 14.8571,  1.1429,  5.9429, 10.4000,  1.5072,  8.3200,  4.0000,\n",
      "         8.3200,  4.7273, 26.0000,  2.6667,  1.4054, 29.7143], device='cuda:0')\n",
      "Pos Weight for Subnarrative: tensor([  1.0000,   9.0435,  13.0000,   7.1724,   6.9333,  34.6667,   8.6667,\n",
      "          7.7037,  10.9474,   4.0784,   8.6667,   2.6667,  14.8571,   3.5862,\n",
      "          4.8372,   8.3200,  18.9091,   1.6378,   5.4737,   5.9429, 208.0000,\n",
      "        104.0000,  16.0000,  20.8000,   4.9524,   6.9333,   4.9524,  10.9474,\n",
      "         69.3333,   9.9048,   8.3200,  13.8667,   2.8493,  16.0000,  23.1111,\n",
      "         16.0000,  18.9091,  18.9091,   7.7037,  11.5556,   4.0784, 104.0000,\n",
      "          2.7368,  34.6667,  41.6000,  41.6000,  14.8571,   6.7097,   5.4737,\n",
      "          5.9429,  20.8000,  11.5556,  18.9091,  69.3333,  34.6667,   2.5366,\n",
      "          6.7097,  13.8667,  16.0000,  13.8667,  26.0000,  69.3333,   6.5000,\n",
      "          8.3200,  69.3333,  52.0000,   8.6667,  10.4000,  11.5556,   7.4286,\n",
      "        208.0000,   5.4737, 104.0000,   3.0145,  23.1111,  69.3333, 104.0000,\n",
      "        208.0000,  41.6000,  26.0000, 104.0000,  69.3333,   7.4286,   1.9623,\n",
      "         18.9091,  52.0000,   3.1045,  52.0000, 208.0000, 104.0000, 208.0000,\n",
      "        208.0000, 208.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "all_dataset = DocumentDataset(data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "\n",
    "\n",
    "# get the labels\n",
    "narrative_targets = torch.stack([torch.tensor(target[2]) for target in all_dataset]).to(device)\n",
    "subnarrative_targets = torch.stack([torch.tensor(target[3]) for target in all_dataset]).to(device)\n",
    "\n",
    "# Compute the class weights for both narrative and sub_narrative\n",
    "narrative_class_weights = narrative_targets.sum(dim=0)  # Sum along rows (class-wise sum)\n",
    "subnarrative_class_weights = subnarrative_targets.sum(dim=0)  # Sum along rows (class-wise sum)\n",
    "\n",
    "# Normalize the class weights by dividing by the maximum class weight\n",
    "pos_weight_narrative = (narrative_class_weights.max() / narrative_class_weights).to(device)\n",
    "pos_weight_subnarrative = (subnarrative_class_weights.max() / subnarrative_class_weights).to(device)\n",
    "\n",
    "\n",
    "print(\"Narrative Class Weights:\", narrative_class_weights)\n",
    "print(\"Subnarrative Class Weights:\", subnarrative_class_weights)\n",
    "print(\"Pos Weight for Narrative:\", pos_weight_narrative)\n",
    "print(\"Pos Weight for Subnarrative:\", pos_weight_subnarrative)\n",
    "\n",
    "# update the loss functions\n",
    "criterion_narrative_weighted = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_narrative)\n",
    "criterion_subnarrative_weighted = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_subnarrative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e037072203bdfec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:26:09.301137Z",
     "start_time": "2025-01-23T14:25:39.606640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "Train Loss: 1.4879\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 0.9537\n",
      "  Precision: 0.9538\n",
      "  Recall: 0.9537\n",
      "  F1-Score: 0.9537\n",
      "  Confusion Matrix:\n",
      "[[384  15]\n",
      " [ 22 378]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.2203\n",
      "  Recall: 0.1121\n",
      "  F1-Score: 0.1279\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.3472\n",
      "  Recall: 0.1701\n",
      "  F1-Score: 0.2283\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0397\n",
      "  Recall: 0.0258\n",
      "  F1-Score: 0.0249\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.2800\n",
      "  Recall: 0.0725\n",
      "  F1-Score: 0.1152\n",
      "==================================================\n",
      "Epoch 201/201\n",
      "Train Loss: 0.0058\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[399   0]\n",
      " [  0 400]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.2203\n",
      "  Recall: 0.1121\n",
      "  F1-Score: 0.1279\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.3472\n",
      "  Recall: 0.1701\n",
      "  F1-Score: 0.2283\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0397\n",
      "  Recall: 0.0258\n",
      "  F1-Score: 0.0249\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.2800\n",
      "  Recall: 0.0725\n",
      "  F1-Score: 0.1152\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# weighted model\n",
    "model_weighted = LTSMModel(vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_weighted.to(device)\n",
    "\n",
    "criterion_lang_weighted = nn.CrossEntropyLoss()\n",
    "optimizer_weighted = optim.Adam(model_weighted.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 201\n",
    "for epoch in range(num_epochs):\n",
    "    model_weighted.train()\n",
    "    train_loss = 0\n",
    "    all_lang_preds, all_lang_targets = [], []\n",
    "    all_narrative_preds, all_narrative_targets = [], []\n",
    "    all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "    for inputs, lang_targets, narrative_targets, subnarrative_targets in train_loader:\n",
    "        inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "            inputs.to(device),\n",
    "            lang_targets.to(device),\n",
    "            narrative_targets.to(device),\n",
    "            subnarrative_targets.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer_weighted.zero_grad()\n",
    "        # forward pass\n",
    "        lang_out, narrative_out, subnarrative_out = model_weighted(inputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss_lang = criterion_lang_weighted(lang_out, lang_targets)\n",
    "        loss_narrative = criterion_narrative_weighted(narrative_out, narrative_targets)\n",
    "        loss_subnarrative = criterion_subnarrative_weighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "        loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "        loss.backward()\n",
    "        optimizer_weighted.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # predictions\n",
    "        lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "        all_lang_preds.extend(lang_preds)\n",
    "        all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "        narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_narrative_preds.extend(narrative_preds)\n",
    "        all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "        subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_subnarrative_preds.extend(subnarrative_preds)\n",
    "        all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "    #  Metrics\n",
    "    lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "    lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "    # Compute Metrics for Narrative (Multi-Label) Classification\n",
    "    narrative_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "    narrative_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "    narrative_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Compute Metrics for Sub-Narrative (Multi-Label) Classification\n",
    "    subnarrative_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "    subnarrative_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "    subnarrative_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Log Epoch Results\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(\"\\nLanguage Classification Metrics:\")\n",
    "        print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "        print(f\"  Precision: {lang_precision:.4f}\")\n",
    "        print(f\"  Recall: {lang_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efd7a04d46a5efee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:59:07.063023Z",
     "start_time": "2025-01-22T21:59:07.000066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.8921\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[41  0]\n",
      " [ 0 35]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1184\n",
      "  Precision: 0.1879\n",
      "  Recall: 0.0955\n",
      "  F1-Score: 0.1155\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1184\n",
      "  Precision: 0.4068\n",
      "  Recall: 0.1633\n",
      "  F1-Score: 0.2330\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.0789\n",
      "  Precision: 0.0497\n",
      "  Recall: 0.0269\n",
      "  F1-Score: 0.0288\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.0789\n",
      "  Precision: 0.3636\n",
      "  Recall: 0.0829\n",
      "  F1-Score: 0.1350\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Validation Loop\n",
    "train_loss = 0\n",
    "all_lang_preds, all_lang_targets = [], []\n",
    "all_narrative_preds, all_narrative_targets = [], []\n",
    "all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "for inputs, lang_targets, narrative_targets, subnarrative_targets in val_loader:\n",
    "    inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "        inputs.to(device),\n",
    "        lang_targets.to(device),\n",
    "        narrative_targets.to(device),\n",
    "        subnarrative_targets.to(device),\n",
    "    )\n",
    "    # forward pass\n",
    "    lang_out, narrative_out, subnarrative_out = model_weighted(inputs)\n",
    "\n",
    "    # backward pass\n",
    "    loss_lang = criterion_lang_weighted(lang_out, lang_targets)\n",
    "    loss_narrative = criterion_narrative_weighted(narrative_out, narrative_targets)\n",
    "    loss_subnarrative = criterion_subnarrative_weighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "    loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # predictions\n",
    "    lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "    all_lang_preds.extend(lang_preds)\n",
    "    all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "    narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_narrative_preds.extend(narrative_preds)\n",
    "    all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "    subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_subnarrative_preds.extend(subnarrative_preds)\n",
    "    all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "#  Metrics\n",
    "lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "# Narrative Metrics\n",
    "narrative_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "narrative_micro_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Sub-Narrative Metrics\n",
    "subnarrative_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "subnarrative_micro_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Log Epoch Results\n",
    "print(f\"Validation Loss: {train_loss / len(val_loader):.4f}\")\n",
    "print(\"\\nLanguage Classification Metrics:\")\n",
    "print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lang_precision:.4f}\")\n",
    "print(f\"  Recall: {lang_recall:.4f}\")\n",
    "print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {narrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {narrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716a26ebdbf3249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T00:21:25.618340Z",
     "start_time": "2025-01-21T00:21:25.616573Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4051cfd3997418e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-2024.3",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
