{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606227292e7ac094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:06:53.166313Z",
     "start_time": "2025-01-22T21:06:53.094199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>narrative</th>\n",
       "      <th>sub_narrative</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>narrative_labels</th>\n",
       "      <th>sub_narrative_labels</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154.0</td>\n",
       "      <td>EN_CC_200254.txt</td>\n",
       "      <td>CC: Hidden plots by secret schemes of powerful...</td>\n",
       "      <td>CC: Hidden plots by secret schemes of powerful...</td>\n",
       "      <td>Biden regime's war on your appliances just wid...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['CC: Hidden plots by secret schemes of powerf...</td>\n",
       "      <td>['CC: Hidden plots by secret schemes of powerf...</td>\n",
       "      <td>biden regime war appliance widen new attack di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215.0</td>\n",
       "      <td>EN_UA_017310.txt</td>\n",
       "      <td>URW: Discrediting the West, Diplomacy;URW: Dis...</td>\n",
       "      <td>URW: Discrediting the West, Diplomacy: The Wes...</td>\n",
       "      <td>Jake Sullivan hints US won’t replenish controv...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['URW: Discrediting the West, Diplomacy', 'URW...</td>\n",
       "      <td>['URW: Discrediting the West, Diplomacy: The W...</td>\n",
       "      <td>jake sullivan hint win replenish controversial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279.0</td>\n",
       "      <td>EN_UA_024050.txt</td>\n",
       "      <td>URW: Blaming the war on others rather than the...</td>\n",
       "      <td>URW: Blaming the war on others rather than the...</td>\n",
       "      <td>How NATO powers are using the U.K.’s World War...</td>\n",
       "      <td>EN</td>\n",
       "      <td>['URW: Blaming the war on others rather than t...</td>\n",
       "      <td>['URW: Blaming the war on others rather than t...</td>\n",
       "      <td>nato power u.k world war model lure russia big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>671.0</td>\n",
       "      <td>PT_342.txt</td>\n",
       "      <td>URW: Russia is the Victim;URW: Discrediting th...</td>\n",
       "      <td>URW: Russia is the Victim: UA is anti-RU extre...</td>\n",
       "      <td>Do discurso do Representante Permanente V. A. ...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['URW: Russia is the Victim', 'URW: Discrediti...</td>\n",
       "      <td>['URW: Russia is the Victim: UA is anti-RU ext...</td>\n",
       "      <td>discurso representante permanente v. A. nebenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716.0</td>\n",
       "      <td>PT_123.txt</td>\n",
       "      <td>URW: Praise of Russia;URW: Discrediting Ukrain...</td>\n",
       "      <td>URW: Praise of Russia: Russia is a guarantor o...</td>\n",
       "      <td>Rússia disponível para negociar com Zelensky m...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['URW: Praise of Russia', 'URW: Discrediting U...</td>\n",
       "      <td>['URW: Praise of Russia: Russia is a guarantor...</td>\n",
       "      <td>Rússia disponível negociar zelensky questionar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PT_207.txt</td>\n",
       "      <td>CC: Criticism of institutions and authorities;...</td>\n",
       "      <td>CC: Criticism of institutions and authorities:...</td>\n",
       "      <td>Zequinha critica UE por adiar obrigatoriedade ...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>zequinha critico ue adiar obrigatoriedade pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PT_217.txt</td>\n",
       "      <td>CC: Amplifying Climate Fears;CC: Amplifying Cl...</td>\n",
       "      <td>CC: Amplifying Climate Fears: Other;CC: Amplif...</td>\n",
       "      <td>O que é a cúpula de calor? Entenda fenómeno qu...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Amplifying Climate Fears', 'CC: Amplifyi...</td>\n",
       "      <td>['CC: Amplifying Climate Fears: Other', 'CC: A...</td>\n",
       "      <td>cúpula calor entenda fenómeno prender ar quent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PT_204.txt</td>\n",
       "      <td>CC: Amplifying Climate Fears;CC: Amplifying Cl...</td>\n",
       "      <td>CC: Amplifying Climate Fears: Amplifying exist...</td>\n",
       "      <td>COP28: Papa Francisco planeia participar nas n...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Amplifying Climate Fears', 'CC: Amplifyi...</td>\n",
       "      <td>['CC: Amplifying Climate Fears: Amplifying exi...</td>\n",
       "      <td>cop papa Francisco planear participar negociaç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PT_229.txt</td>\n",
       "      <td>CC: Amplifying Climate Fears</td>\n",
       "      <td>CC: Amplifying Climate Fears: Amplifying exist...</td>\n",
       "      <td>Queda do tráfego pelo Canal do Panamá pode cus...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Amplifying Climate Fears']</td>\n",
       "      <td>['CC: Amplifying Climate Fears: Amplifying exi...</td>\n",
       "      <td>queda tráfego canal panamá custar milhão dólar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PT_225.txt</td>\n",
       "      <td>CC: Criticism of institutions and authorities;...</td>\n",
       "      <td>CC: Criticism of institutions and authorities:...</td>\n",
       "      <td>Projetos no Congresso trarão danos irreversíve...</td>\n",
       "      <td>PT</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>['CC: Criticism of institutions and authoritie...</td>\n",
       "      <td>projeto congresso trar dano irreversível ambie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1343 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0          filename  \\\n",
       "0          154.0  EN_CC_200254.txt   \n",
       "1          215.0  EN_UA_017310.txt   \n",
       "2          279.0  EN_UA_024050.txt   \n",
       "3          671.0        PT_342.txt   \n",
       "4          716.0        PT_123.txt   \n",
       "...          ...               ...   \n",
       "1338         NaN        PT_207.txt   \n",
       "1339         NaN        PT_217.txt   \n",
       "1340         NaN        PT_204.txt   \n",
       "1341         NaN        PT_229.txt   \n",
       "1342         NaN        PT_225.txt   \n",
       "\n",
       "                                              narrative  \\\n",
       "0     CC: Hidden plots by secret schemes of powerful...   \n",
       "1     URW: Discrediting the West, Diplomacy;URW: Dis...   \n",
       "2     URW: Blaming the war on others rather than the...   \n",
       "3     URW: Russia is the Victim;URW: Discrediting th...   \n",
       "4     URW: Praise of Russia;URW: Discrediting Ukrain...   \n",
       "...                                                 ...   \n",
       "1338  CC: Criticism of institutions and authorities;...   \n",
       "1339  CC: Amplifying Climate Fears;CC: Amplifying Cl...   \n",
       "1340  CC: Amplifying Climate Fears;CC: Amplifying Cl...   \n",
       "1341                       CC: Amplifying Climate Fears   \n",
       "1342  CC: Criticism of institutions and authorities;...   \n",
       "\n",
       "                                          sub_narrative  \\\n",
       "0     CC: Hidden plots by secret schemes of powerful...   \n",
       "1     URW: Discrediting the West, Diplomacy: The Wes...   \n",
       "2     URW: Blaming the war on others rather than the...   \n",
       "3     URW: Russia is the Victim: UA is anti-RU extre...   \n",
       "4     URW: Praise of Russia: Russia is a guarantor o...   \n",
       "...                                                 ...   \n",
       "1338  CC: Criticism of institutions and authorities:...   \n",
       "1339  CC: Amplifying Climate Fears: Other;CC: Amplif...   \n",
       "1340  CC: Amplifying Climate Fears: Amplifying exist...   \n",
       "1341  CC: Amplifying Climate Fears: Amplifying exist...   \n",
       "1342  CC: Criticism of institutions and authorities:...   \n",
       "\n",
       "                                                   text language  \\\n",
       "0     Biden regime's war on your appliances just wid...       EN   \n",
       "1     Jake Sullivan hints US won’t replenish controv...       EN   \n",
       "2     How NATO powers are using the U.K.’s World War...       EN   \n",
       "3     Do discurso do Representante Permanente V. A. ...       PT   \n",
       "4     Rússia disponível para negociar com Zelensky m...       PT   \n",
       "...                                                 ...      ...   \n",
       "1338  Zequinha critica UE por adiar obrigatoriedade ...       PT   \n",
       "1339  O que é a cúpula de calor? Entenda fenómeno qu...       PT   \n",
       "1340  COP28: Papa Francisco planeia participar nas n...       PT   \n",
       "1341  Queda do tráfego pelo Canal do Panamá pode cus...       PT   \n",
       "1342  Projetos no Congresso trarão danos irreversíve...       PT   \n",
       "\n",
       "                                       narrative_labels  \\\n",
       "0     ['CC: Hidden plots by secret schemes of powerf...   \n",
       "1     ['URW: Discrediting the West, Diplomacy', 'URW...   \n",
       "2     ['URW: Blaming the war on others rather than t...   \n",
       "3     ['URW: Russia is the Victim', 'URW: Discrediti...   \n",
       "4     ['URW: Praise of Russia', 'URW: Discrediting U...   \n",
       "...                                                 ...   \n",
       "1338  ['CC: Criticism of institutions and authoritie...   \n",
       "1339  ['CC: Amplifying Climate Fears', 'CC: Amplifyi...   \n",
       "1340  ['CC: Amplifying Climate Fears', 'CC: Amplifyi...   \n",
       "1341                   ['CC: Amplifying Climate Fears']   \n",
       "1342  ['CC: Criticism of institutions and authoritie...   \n",
       "\n",
       "                                   sub_narrative_labels  \\\n",
       "0     ['CC: Hidden plots by secret schemes of powerf...   \n",
       "1     ['URW: Discrediting the West, Diplomacy: The W...   \n",
       "2     ['URW: Blaming the war on others rather than t...   \n",
       "3     ['URW: Russia is the Victim: UA is anti-RU ext...   \n",
       "4     ['URW: Praise of Russia: Russia is a guarantor...   \n",
       "...                                                 ...   \n",
       "1338  ['CC: Criticism of institutions and authoritie...   \n",
       "1339  ['CC: Amplifying Climate Fears: Other', 'CC: A...   \n",
       "1340  ['CC: Amplifying Climate Fears: Amplifying exi...   \n",
       "1341  ['CC: Amplifying Climate Fears: Amplifying exi...   \n",
       "1342  ['CC: Criticism of institutions and authoritie...   \n",
       "\n",
       "                                                cleaned  \n",
       "0     biden regime war appliance widen new attack di...  \n",
       "1     jake sullivan hint win replenish controversial...  \n",
       "2     nato power u.k world war model lure russia big...  \n",
       "3     discurso representante permanente v. A. nebenz...  \n",
       "4     Rússia disponível negociar zelensky questionar...  \n",
       "...                                                 ...  \n",
       "1338  zequinha critico ue adiar obrigatoriedade pres...  \n",
       "1339  cúpula calor entenda fenómeno prender ar quent...  \n",
       "1340  cop papa Francisco planear participar negociaç...  \n",
       "1341  queda tráfego canal panamá custar milhão dólar...  \n",
       "1342  projeto congresso trar dano irreversível ambie...  \n",
       "\n",
       "[1343 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load datasets\n",
    "training_data = pd.read_csv(\"balanced_training_data.csv\")\n",
    "target_data = pd.read_csv(\"target.csv\")\n",
    "\n",
    "# Concatenate the dataframes for later usage (axis=0)\n",
    "data = pd.concat([training_data, target_data], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "len_texts = [len(x) for x in data['cleaned']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923ffcdd9c29f262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:25.466360Z",
     "start_time": "2025-01-22T21:11:25.461426Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "# label mappings\n",
    "def build_vocab_and_labels(data):\n",
    "    word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    label_to_idx = {\"Other\": 0}\n",
    "    sublabel_to_idx = {\"Other\": 0}\n",
    "    language_to_idx = {\"EN\": 0, \"PT\": 1}\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # index the vocab\n",
    "        for word in tokenize(row[\"cleaned\"]):\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = len(word_to_idx)\n",
    "        # index the labels\n",
    "        for label in row[\"narrative\"].split(\";\"):\n",
    "            if label not in label_to_idx:\n",
    "                label_to_idx[label] = len(label_to_idx)\n",
    "        for sublabel in row[\"sub_narrative\"].split(\";\"):\n",
    "            if sublabel not in sublabel_to_idx:\n",
    "                sublabel_to_idx[sublabel] = len(sublabel_to_idx)\n",
    "\n",
    "    return word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d0abcb9e8de0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:26.181203Z",
     "start_time": "2025-01-22T21:11:26.054520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16989"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx = build_vocab_and_labels(data)\n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd7169851e7df37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:26.630190Z",
     "start_time": "2025-01-22T21:11:26.626593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fdc521ceee5493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:27.190062Z",
     "start_time": "2025-01-22T21:11:27.186395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(sublabel_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f932c06f6d034780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:27.853608Z",
     "start_time": "2025-01-22T21:11:27.846431Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, df, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx, max_len=50):\n",
    "        self.data = df\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.sublabel_to_idx = sublabel_to_idx\n",
    "        self.language_to_idx = language_to_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tokens = tokenize(row[\"text\"])\n",
    "        # assign the unk index if the word isn't indexed already\n",
    "        input_ids = [self.word_to_idx.get(word, self.word_to_idx[\"<UNK>\"]) for word in tokens]\n",
    "        # make sure the length is always 50 through padding if needed\n",
    "        input_ids = input_ids[:self.max_len] + [self.word_to_idx[\"<PAD>\"]] * (self.max_len - len(input_ids))\n",
    "\n",
    "        narrative_labels = [self.label_to_idx[label] for label in row[\"narrative\"].split(\";\")]\n",
    "        subnarrative_labels = [self.sublabel_to_idx[label] for label in row[\"sub_narrative\"].split(\";\")]\n",
    "\n",
    "        # Multi-label one-hot encoding\n",
    "        narrative_targets = torch.zeros(len(self.label_to_idx))\n",
    "        narrative_targets[narrative_labels] = 1\n",
    "\n",
    "        subnarrative_targets = torch.zeros(len(self.sublabel_to_idx))\n",
    "        subnarrative_targets[subnarrative_labels] = 1\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(self.language_to_idx[row[\"language\"]], dtype=torch.long),\n",
    "            narrative_targets,\n",
    "            subnarrative_targets\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84c47c4392463dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:29.897376Z",
     "start_time": "2025-01-22T21:11:29.893693Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = DocumentDataset(training_data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "val_dataset = DocumentDataset(target_data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e675f4b43e7db2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:30.470528Z",
     "start_time": "2025-01-22T21:11:30.465483Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM Model with an embedding layer and three classifiers in th end\n",
    "class LTSMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives):\n",
    "        super(LTSMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.lang_classifier = nn.Linear(hidden_dim, num_languages)\n",
    "        self.narrative_classifier = nn.Linear(hidden_dim, num_narratives)\n",
    "        self.subnarrative_classifier = nn.Linear(hidden_dim, num_subnarratives)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = hidden.squeeze(0)\n",
    "\n",
    "        lang_out = self.lang_classifier(hidden)\n",
    "        narrative_out = self.narrative_classifier(hidden)\n",
    "        subnarrative_out = self.subnarrative_classifier(hidden)\n",
    "\n",
    "        return lang_out, narrative_out, subnarrative_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea3b50f54f36dc76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:11:31.285712Z",
     "start_time": "2025-01-22T21:11:31.209737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 25910386\n",
      "Trainable parameters: 25910386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "embed_dim = 1024\n",
    "hidden_dim = 1024\n",
    "num_languages = len(language_to_idx)\n",
    "num_narratives = len(label_to_idx)\n",
    "num_subnarratives = len(sublabel_to_idx)\n",
    "\n",
    "# the unweighted model to the gpu\n",
    "model_unweighted = LTSMModel(vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_unweighted.to(device)\n",
    "\n",
    "# the unweighted loss fucntions\n",
    "criterion_lang_unweighted = nn.CrossEntropyLoss()\n",
    "criterion_bce_unweighted = nn.BCEWithLogitsLoss()\n",
    "optimizer_unweighted = optim.Adam(model_unweighted.parameters(), lr=0.001)\n",
    "# Calculate the number of parameters\n",
    "total_params = sum(p.numel() for p in model_unweighted.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_unweighted.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f1936da3de8388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:12:06.897060Z",
     "start_time": "2025-01-22T21:11:34.352054Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "Train Loss: 0.8567\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 0.8603\n",
      "  Precision: 0.8601\n",
      "  Recall: 0.8603\n",
      "  F1-Score: 0.8601\n",
      "  Confusion Matrix:\n",
      "[[453  96]\n",
      " [ 81 637]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.1551\n",
      "  Recall: 0.0494\n",
      "  F1-Score: 0.0710\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.3743\n",
      "  Recall: 0.0961\n",
      "  F1-Score: 0.1529\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0422\n",
      "  Recall: 0.0169\n",
      "  F1-Score: 0.0197\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.0481\n",
      "  Recall: 0.0191\n",
      "  F1-Score: 0.0273\n",
      "==================================================\n",
      "Epoch 201/201\n",
      "Train Loss: 0.0020\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[549   0]\n",
      " [  0 718]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.9983\n",
      "  Recall: 0.9936\n",
      "  F1-Score: 0.9959\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.9979\n",
      "  Recall: 0.9968\n",
      "  F1-Score: 0.9973\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.9873\n",
      "  Recall: 0.9852\n",
      "  F1-Score: 0.9862\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.9964\n",
      "  Recall: 0.9945\n",
      "  F1-Score: 0.9955\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 201\n",
    "for epoch in range(num_epochs):\n",
    "    model_unweighted.train()\n",
    "    train_loss = 0\n",
    "    all_lang_preds, all_lang_targets = [], []\n",
    "    all_narrative_preds, all_narrative_targets = [], []\n",
    "    all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "    for inputs, lang_targets, narrative_targets, subnarrative_targets in train_loader:\n",
    "        inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "            inputs.to(device),\n",
    "            lang_targets.to(device),\n",
    "            narrative_targets.to(device),\n",
    "            subnarrative_targets.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer_unweighted.zero_grad()\n",
    "        # forward pass\n",
    "        lang_out, narrative_out, subnarrative_out = model_unweighted(inputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss_lang = criterion_lang_unweighted(lang_out, lang_targets)\n",
    "        loss_narrative = criterion_bce_unweighted(narrative_out, narrative_targets)\n",
    "        loss_subnarrative = criterion_bce_unweighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "        loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "        loss.backward()\n",
    "        optimizer_unweighted.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # predictions\n",
    "        lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "        all_lang_preds.extend(lang_preds)\n",
    "        all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "        narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_narrative_preds.extend(narrative_preds)\n",
    "        all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "        subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_subnarrative_preds.extend(subnarrative_preds)\n",
    "        all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "    lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "    narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "    narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "    narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "    narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "    narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "    subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "    subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "    subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "    subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "    # Log Epoch Results\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(\"\\nLanguage Classification Metrics:\")\n",
    "        print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "        print(f\"  Precision: {lang_precision:.4f}\")\n",
    "        print(f\"  Recall: {lang_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db148daed40f4d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:58:25.038016Z",
     "start_time": "2025-01-22T21:58:24.957590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0275\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[41  0]\n",
      " [ 0 35]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.2763\n",
      "  Precision: 0.1902\n",
      "  Recall: 0.1323\n",
      "  F1-Score: 0.1379\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.2763\n",
      "  Precision: 0.5429\n",
      "  Recall: 0.2585\n",
      "  F1-Score: 0.3502\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1316\n",
      "  Precision: 0.0449\n",
      "  Recall: 0.0322\n",
      "  F1-Score: 0.0315\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1316\n",
      "  Precision: 0.4038\n",
      "  Recall: 0.1088\n",
      "  F1-Score: 0.1714\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Validation Loop\n",
    "train_loss = 0\n",
    "all_lang_preds, all_lang_targets = [], []\n",
    "all_narrative_preds, all_narrative_targets = [], []\n",
    "all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "for inputs, lang_targets, narrative_targets, subnarrative_targets in val_loader:\n",
    "    inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "        inputs.to(device),\n",
    "        lang_targets.to(device),\n",
    "        narrative_targets.to(device),\n",
    "        subnarrative_targets.to(device),\n",
    "    )\n",
    "    # forward pass\n",
    "    lang_out, narrative_out, subnarrative_out = model_unweighted(inputs)\n",
    "\n",
    "    # Losses\n",
    "    loss_lang = criterion_lang_unweighted(lang_out, lang_targets)\n",
    "    loss_narrative = criterion_bce_unweighted(narrative_out, narrative_targets)\n",
    "    loss_subnarrative = criterion_bce_unweighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "    loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # predictions\n",
    "    lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "    all_lang_preds.extend(lang_preds)\n",
    "    all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "    narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_narrative_preds.extend(narrative_preds)\n",
    "    all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "    subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_subnarrative_preds.extend(subnarrative_preds)\n",
    "    all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "    \n",
    "#  Metrics\n",
    "lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "# Narrative Metrics\n",
    "narrative_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "narrative_micro_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Sub-Narrative Metrics\n",
    "subnarrative_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "subnarrative_micro_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Log Epoch Results\n",
    "print(f\"Validation Loss: {train_loss / len(val_loader):.4f}\")\n",
    "print(\"\\nLanguage Classification Metrics:\")\n",
    "print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lang_precision:.4f}\")\n",
    "print(f\"  Recall: {lang_recall:.4f}\")\n",
    "print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {narrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {narrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25faa9f7585b66b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:12:28.251255Z",
     "start_time": "2025-01-22T21:12:27.878020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10258/1170623561.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  narrative_targets = torch.stack([torch.tensor(target[2]) for target in all_dataset]).to(device)\n",
      "/tmp/ipykernel_10258/1170623561.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  subnarrative_targets = torch.stack([torch.tensor(target[3]) for target in all_dataset]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrative Class Weights: tensor([103., 130., 149., 246., 434.,  53., 218., 235., 345., 310., 429., 101.,\n",
      "        133., 138.,  71., 165.,  79.,  91.,  20.,  50.,  21.,  19.],\n",
      "       device='cuda:0')\n",
      "Subnarrative Class Weights: tensor([103.,  82.,  59.,  60., 145.,  42., 300.,  18., 133.,  35.,  87., 154.,\n",
      "         64.,  31.,  57.,  37., 212., 131.,  30., 180., 118., 151.,  90., 165.,\n",
      "        104.,  38., 100.,  67.,  23., 111.,   4.,  82.,  54.,  48.,  79.,  19.,\n",
      "         68.,  56., 129.,  29.,  23.,  21.,  37., 100.,  39.,  23.,  43.,   7.,\n",
      "         33.,  37.,  52.,  21.,  17.,   5.,  58.,  15., 131.,   7.,  76.,  36.,\n",
      "         75., 101.,  13.,  21.,  48.,  88.,   3.,  16.,   7.,  43.,  67.,  29.,\n",
      "          8.,  18.,   6.,  19.,   5.,  26.,   6.,  10.,  20.,  23.,   4.,   5.,\n",
      "          8.,   5.,   4.,   1.,   6.,   1.], device='cuda:0')\n",
      "Pos Weight for Narrative: tensor([ 4.2136,  3.3385,  2.9128,  1.7642,  1.0000,  8.1887,  1.9908,  1.8468,\n",
      "         1.2580,  1.4000,  1.0117,  4.2970,  3.2632,  3.1449,  6.1127,  2.6303,\n",
      "         5.4937,  4.7692, 21.7000,  8.6800, 20.6667, 22.8421], device='cuda:0')\n",
      "Pos Weight for Subnarrative: tensor([  2.9126,   3.6585,   5.0847,   5.0000,   2.0690,   7.1429,   1.0000,\n",
      "         16.6667,   2.2556,   8.5714,   3.4483,   1.9481,   4.6875,   9.6774,\n",
      "          5.2632,   8.1081,   1.4151,   2.2901,  10.0000,   1.6667,   2.5424,\n",
      "          1.9868,   3.3333,   1.8182,   2.8846,   7.8947,   3.0000,   4.4776,\n",
      "         13.0435,   2.7027,  75.0000,   3.6585,   5.5556,   6.2500,   3.7975,\n",
      "         15.7895,   4.4118,   5.3571,   2.3256,  10.3448,  13.0435,  14.2857,\n",
      "          8.1081,   3.0000,   7.6923,  13.0435,   6.9767,  42.8571,   9.0909,\n",
      "          8.1081,   5.7692,  14.2857,  17.6471,  60.0000,   5.1724,  20.0000,\n",
      "          2.2901,  42.8571,   3.9474,   8.3333,   4.0000,   2.9703,  23.0769,\n",
      "         14.2857,   6.2500,   3.4091, 100.0000,  18.7500,  42.8571,   6.9767,\n",
      "          4.4776,  10.3448,  37.5000,  16.6667,  50.0000,  15.7895,  60.0000,\n",
      "         11.5385,  50.0000,  30.0000,  15.0000,  13.0435,  75.0000,  60.0000,\n",
      "         37.5000,  60.0000,  75.0000, 300.0000,  50.0000, 300.0000],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "all_dataset = DocumentDataset(data, word_to_idx, label_to_idx, sublabel_to_idx, language_to_idx)\n",
    "\n",
    "\n",
    "# get the labels\n",
    "narrative_targets = torch.stack([torch.tensor(target[2]) for target in all_dataset]).to(device)\n",
    "subnarrative_targets = torch.stack([torch.tensor(target[3]) for target in all_dataset]).to(device)\n",
    "\n",
    "# Compute the class weights for both narrative and sub_narrative\n",
    "narrative_class_weights = narrative_targets.sum(dim=0)  # Sum along rows (class-wise sum)\n",
    "subnarrative_class_weights = subnarrative_targets.sum(dim=0)  # Sum along rows (class-wise sum)\n",
    "\n",
    "# Normalize the class weights by dividing by the maximum class weight\n",
    "pos_weight_narrative = (narrative_class_weights.max() / narrative_class_weights).to(device)\n",
    "pos_weight_subnarrative = (subnarrative_class_weights.max() / subnarrative_class_weights).to(device)\n",
    "\n",
    "\n",
    "print(\"Narrative Class Weights:\", narrative_class_weights)\n",
    "print(\"Subnarrative Class Weights:\", subnarrative_class_weights)\n",
    "print(\"Pos Weight for Narrative:\", pos_weight_narrative)\n",
    "print(\"Pos Weight for Subnarrative:\", pos_weight_subnarrative)\n",
    "\n",
    "# update the loss functions\n",
    "criterion_narrative_weighted = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_narrative)\n",
    "criterion_subnarrative_weighted = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_subnarrative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e037072203bdfec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:26:09.301137Z",
     "start_time": "2025-01-23T14:25:39.606640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/201\n",
      "Train Loss: 1.4689\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 0.8666\n",
      "  Precision: 0.8664\n",
      "  Recall: 0.8666\n",
      "  F1-Score: 0.8663\n",
      "  Confusion Matrix:\n",
      "[[455  94]\n",
      " [ 75 643]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.1902\n",
      "  Recall: 0.1323\n",
      "  F1-Score: 0.1379\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.5429\n",
      "  Recall: 0.2585\n",
      "  F1-Score: 0.3502\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0449\n",
      "  Recall: 0.0322\n",
      "  F1-Score: 0.0315\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.4038\n",
      "  Recall: 0.1088\n",
      "  F1-Score: 0.1714\n",
      "==================================================\n",
      "Epoch 201/201\n",
      "Train Loss: 0.0033\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[549   0]\n",
      " [  0 718]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.1902\n",
      "  Recall: 0.1323\n",
      "  F1-Score: 0.1379\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.5429\n",
      "  Recall: 0.2585\n",
      "  F1-Score: 0.3502\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Precision: 0.0449\n",
      "  Recall: 0.0322\n",
      "  F1-Score: 0.0315\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Precision: 0.4038\n",
      "  Recall: 0.1088\n",
      "  F1-Score: 0.1714\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# weighted model\n",
    "model_weighted = LTSMModel(vocab_size, embed_dim, hidden_dim, num_languages, num_narratives, num_subnarratives)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_weighted.to(device)\n",
    "\n",
    "criterion_lang_weighted = nn.CrossEntropyLoss()\n",
    "optimizer_weighted = optim.Adam(model_weighted.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 201\n",
    "for epoch in range(num_epochs):\n",
    "    model_weighted.train()\n",
    "    train_loss = 0\n",
    "    all_lang_preds, all_lang_targets = [], []\n",
    "    all_narrative_preds, all_narrative_targets = [], []\n",
    "    all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "    for inputs, lang_targets, narrative_targets, subnarrative_targets in train_loader:\n",
    "        inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "            inputs.to(device),\n",
    "            lang_targets.to(device),\n",
    "            narrative_targets.to(device),\n",
    "            subnarrative_targets.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer_weighted.zero_grad()\n",
    "        # forward pass\n",
    "        lang_out, narrative_out, subnarrative_out = model_weighted(inputs)\n",
    "\n",
    "        # backward pass\n",
    "        loss_lang = criterion_lang_weighted(lang_out, lang_targets)\n",
    "        loss_narrative = criterion_narrative_weighted(narrative_out, narrative_targets)\n",
    "        loss_subnarrative = criterion_subnarrative_weighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "        loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "        loss.backward()\n",
    "        optimizer_weighted.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # predictions\n",
    "        lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "        all_lang_preds.extend(lang_preds)\n",
    "        all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "        narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_narrative_preds.extend(narrative_preds)\n",
    "        all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "        subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "        all_subnarrative_preds.extend(subnarrative_preds)\n",
    "        all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "    #  Metrics\n",
    "    lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "    lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "    lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "    # Compute Metrics for Narrative (Multi-Label) Classification\n",
    "    narrative_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "    narrative_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "    narrative_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Compute Metrics for Sub-Narrative (Multi-Label) Classification\n",
    "    subnarrative_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "    subnarrative_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "    subnarrative_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Log Epoch Results\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(\"\\nLanguage Classification Metrics:\")\n",
    "        print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "        print(f\"  Precision: {lang_precision:.4f}\")\n",
    "        print(f\"  Recall: {lang_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "        print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "        print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "        print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "        print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd7a04d46a5efee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T21:59:07.063023Z",
     "start_time": "2025-01-22T21:59:07.000066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.8488\n",
      "\n",
      "Language Classification Metrics:\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1-Score: 1.0000\n",
      "  Confusion Matrix:\n",
      "[[41  0]\n",
      " [ 0 35]]\n",
      "\n",
      "Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.2368\n",
      "  Precision: 0.1732\n",
      "  Recall: 0.1143\n",
      "  F1-Score: 0.1171\n",
      "\n",
      "Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.2368\n",
      "  Precision: 0.4189\n",
      "  Recall: 0.2109\n",
      "  F1-Score: 0.2805\n",
      "\n",
      "Sub-Narrative Classification Metrics (Macro Average):\n",
      "  Accuracy: 0.1316\n",
      "  Precision: 0.0423\n",
      "  Recall: 0.0293\n",
      "  F1-Score: 0.0273\n",
      "\n",
      "Sub-Narrative Classification Metrics (Micro Average):\n",
      "  Accuracy: 0.1316\n",
      "  Precision: 0.3621\n",
      "  Recall: 0.1088\n",
      "  F1-Score: 0.1673\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Validation Loop\n",
    "train_loss = 0\n",
    "all_lang_preds, all_lang_targets = [], []\n",
    "all_narrative_preds, all_narrative_targets = [], []\n",
    "all_subnarrative_preds, all_subnarrative_targets = [], []\n",
    "\n",
    "for inputs, lang_targets, narrative_targets, subnarrative_targets in val_loader:\n",
    "    inputs, lang_targets, narrative_targets, subnarrative_targets = (\n",
    "        inputs.to(device),\n",
    "        lang_targets.to(device),\n",
    "        narrative_targets.to(device),\n",
    "        subnarrative_targets.to(device),\n",
    "    )\n",
    "    # forward pass\n",
    "    lang_out, narrative_out, subnarrative_out = model_weighted(inputs)\n",
    "\n",
    "    # backward pass\n",
    "    loss_lang = criterion_lang_weighted(lang_out, lang_targets)\n",
    "    loss_narrative = criterion_narrative_weighted(narrative_out, narrative_targets)\n",
    "    loss_subnarrative = criterion_subnarrative_weighted(subnarrative_out, subnarrative_targets)\n",
    "\n",
    "    loss = loss_lang + loss_narrative + loss_subnarrative\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    # predictions\n",
    "    lang_preds = lang_out.argmax(dim=1).cpu().numpy()\n",
    "    all_lang_preds.extend(lang_preds)\n",
    "    all_lang_targets.extend(lang_targets.cpu().numpy())\n",
    "\n",
    "    narrative_preds = (torch.sigmoid(narrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_narrative_preds.extend(narrative_preds)\n",
    "    all_narrative_targets.extend(narrative_targets.cpu().numpy())\n",
    "\n",
    "    subnarrative_preds = (torch.sigmoid(subnarrative_out) > 0.5).int().cpu().numpy()\n",
    "    all_subnarrative_preds.extend(subnarrative_preds)\n",
    "    all_subnarrative_targets.extend(subnarrative_targets.cpu().numpy())\n",
    "\n",
    "#  Metrics\n",
    "lang_accuracy = accuracy_score(all_lang_targets, all_lang_preds)\n",
    "lang_precision = precision_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_recall = recall_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_f1 = f1_score(all_lang_targets, all_lang_preds, average=\"weighted\")\n",
    "lang_cm = confusion_matrix(all_lang_targets, all_lang_preds)\n",
    "\n",
    "# Narrative Metrics\n",
    "narrative_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_macro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "narrative_macro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "narrative_micro_accuracy = accuracy_score(all_narrative_targets, all_narrative_preds)\n",
    "narrative_micro_precision = precision_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_recall = recall_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "narrative_micro_f1 = f1_score(all_narrative_targets, all_narrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Sub-Narrative Metrics\n",
    "subnarrative_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_macro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "subnarrative_macro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "subnarrative_micro_accuracy = accuracy_score(all_subnarrative_targets, all_subnarrative_preds)\n",
    "subnarrative_micro_precision = precision_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_recall = recall_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "subnarrative_micro_f1 = f1_score(all_subnarrative_targets, all_subnarrative_preds, average=\"micro\", zero_division=0)\n",
    "\n",
    "# Log Epoch Results\n",
    "print(f\"Validation Loss: {train_loss / len(val_loader):.4f}\")\n",
    "print(\"\\nLanguage Classification Metrics:\")\n",
    "print(f\"  Accuracy: {lang_accuracy:.4f}\")\n",
    "print(f\"  Precision: {lang_precision:.4f}\")\n",
    "print(f\"  Recall: {lang_recall:.4f}\")\n",
    "print(f\"  F1-Score: {lang_f1:.4f}\")\n",
    "print(f\"  Confusion Matrix:\\n{lang_cm}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {narrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nNarrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {narrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {narrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {narrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {narrative_micro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Macro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_macro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_macro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nSub-Narrative Classification Metrics (Micro Average):\")\n",
    "print(f\"  Accuracy: {subnarrative_micro_accuracy:.4f}\")\n",
    "print(f\"  Precision: {subnarrative_micro_precision:.4f}\")\n",
    "print(f\"  Recall: {subnarrative_micro_recall:.4f}\")\n",
    "print(f\"  F1-Score: {subnarrative_micro_f1:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716a26ebdbf3249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T00:21:25.618340Z",
     "start_time": "2025-01-21T00:21:25.616573Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4051cfd3997418e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-2024.3",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
